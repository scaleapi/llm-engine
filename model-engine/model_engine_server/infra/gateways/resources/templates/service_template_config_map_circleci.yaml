---
# Source: model-engine/templates/service_template_config_map.yaml
# THIS FILE IS AUTOGENERATED USING `just autogen-templates`. PLEASE EDIT THE GOTEMPLATE FILE IN THE HELM CHART!!!
apiVersion: v1
kind: ConfigMap
metadata:
  name: model-engine-service-template-config
  labels:
    team: infra
    product: model-engine
    helm.sh/chart: model-engine-0.1.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: a93c7fe34529efde2b468b9cbbf3abf300308164
    tags.datadoghq.com/version: a93c7fe34529efde2b468b9cbbf3abf300308164
    tags.datadoghq.com/env: circleci
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-2"
data:
  deployment-triton-enhanced-runnable-image-async-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
      annotations:
        celery.scaleml.autoscaler/queue: ${QUEUE}
        celery.scaleml.autoscaler/broker: ${BROKER_NAME}
        celery.scaleml.autoscaler/taskVisibility: "VISIBILITY_24H"
        celery.scaleml.autoscaler/perWorker: "${PER_WORKER}"
        celery.scaleml.autoscaler/minWorkers: "${MIN_WORKERS}"
        celery.scaleml.autoscaler/maxWorkers: "${MAX_WORKERS}"
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            sidecar.istio.io/inject: "false"  # TODO: switch to scuttle
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
          priorityClassName: ${PRIORITY}
          containers:
            - name: celery-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.celery_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --queue
                - "${QUEUE}"
                - --task-visibility
                - "VISIBILITY_24H"
                - --set
                - "forwarder.model.args.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.model.args.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --num-workers
                - "${PER_WORKER}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: CELERY_QUEUE
                  value: "${QUEUE}"
                - name: CELERY_TASK_VISIBILITY
                  value: "VISIBILITY_24H"
                - name: S3_BUCKET
                  value: "${CELERY_S3_BUCKET}"
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
            - name: tritonserver
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/std-ml-srv:${TRITON_COMMIT_TAG}-triton
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - bash
                - -c
                - "$TRITON_COMMAND"
              env:
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
              ports:
                - containerPort: 8000
                  name: http
                - containerPort: 8001
                  name: grpc
                - containerPort: 8002
                  name: metrics
              readinessProbe:
                httpGet:
                # Need to have Triton support --http-address IPv6 :(
                # https://github:com/triton-inference-server/server/issues/5305:
                #   path: /v2/health/ready
                #   port: 8000
                  path: /readyz
                  port: 3000
                initialDelaySeconds: $TRITON_READINESS_INITIAL_DELAY
                periodSeconds: 10
              resources:
                requests:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
                limits:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-async-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
      annotations:
        celery.scaleml.autoscaler/queue: ${QUEUE}
        celery.scaleml.autoscaler/broker: ${BROKER_NAME}
        celery.scaleml.autoscaler/taskVisibility: "VISIBILITY_24H"
        celery.scaleml.autoscaler/perWorker: "${PER_WORKER}"
        celery.scaleml.autoscaler/minWorkers: "${MIN_WORKERS}"
        celery.scaleml.autoscaler/maxWorkers: "${MAX_WORKERS}"
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            sidecar.istio.io/inject: "false"  # TODO: switch to scuttle
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
          priorityClassName: ${PRIORITY}
          containers:
            - name: celery-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.celery_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --queue
                - "${QUEUE}"
                - --task-visibility
                - "VISIBILITY_24H"
                - --set
                - "forwarder.model.args.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.model.args.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --num-workers
                - "${PER_WORKER}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: CELERY_QUEUE
                  value: "${QUEUE}"
                - name: CELERY_TASK_VISIBILITY
                  value: "VISIBILITY_24H"
                - name: S3_BUCKET
                  value: "${CELERY_S3_BUCKET}"
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-triton-enhanced-runnable-image-sync-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${PER_WORKER}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: tritonserver
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/std-ml-srv:${TRITON_COMMIT_TAG}-triton
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - bash
                - -c
                - "$TRITON_COMMAND"
              env:
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
              ports:
                - containerPort: 8000
                  name: http
                - containerPort: 8001
                  name: grpc
                - containerPort: 8002
                  name: metrics
              readinessProbe:
                httpGet:
                # Need to have Triton support --http-address IPv6 :(
                # https://github:com/triton-inference-server/server/issues/5305:
                #   path: /v2/health/ready
                #   port: 8000
                  path: /readyz
                  port: 3000
                initialDelaySeconds: $TRITON_READINESS_INITIAL_DELAY
                periodSeconds: 10
              resources:
                requests:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
                limits:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-sync-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${PER_WORKER}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-streaming-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/service--http_forwarder.yaml
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${PER_WORKER}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.stream.predict_route=${STREAMING_PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-triton-enhanced-runnable-image-async-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
      annotations:
        celery.scaleml.autoscaler/queue: ${QUEUE}
        celery.scaleml.autoscaler/broker: ${BROKER_NAME}
        celery.scaleml.autoscaler/taskVisibility: "VISIBILITY_24H"
        celery.scaleml.autoscaler/perWorker: "${PER_WORKER}"
        celery.scaleml.autoscaler/minWorkers: "${MIN_WORKERS}"
        celery.scaleml.autoscaler/maxWorkers: "${MAX_WORKERS}"
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            sidecar.istio.io/inject: "false"  # TODO: switch to scuttle
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: celery-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.celery_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --queue
                - "${QUEUE}"
                - --task-visibility
                - "VISIBILITY_24H"
                - --set
                - "forwarder.model.args.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.model.args.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --num-workers
                - "${PER_WORKER}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: CELERY_QUEUE
                  value: "${QUEUE}"
                - name: CELERY_TASK_VISIBILITY
                  value: "VISIBILITY_24H"
                - name: S3_BUCKET
                  value: "${CELERY_S3_BUCKET}"
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
            - name: tritonserver
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/std-ml-srv:${TRITON_COMMIT_TAG}-triton
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - bash
                - -c
                - "$TRITON_COMMAND"
              env:
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
              ports:
                - containerPort: 8000
                  name: http
                - containerPort: 8001
                  name: grpc
                - containerPort: 8002
                  name: metrics
              readinessProbe:
                httpGet:
                # Need to have Triton support --http-address IPv6 :(
                # https://github:com/triton-inference-server/server/issues/5305:
                #   path: /v2/health/ready
                #   port: 8000
                  path: /readyz
                  port: 3000
                initialDelaySeconds: $TRITON_READINESS_INITIAL_DELAY
                periodSeconds: 10
              resources:
                requests:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
                limits:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-async-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
      annotations:
        celery.scaleml.autoscaler/queue: ${QUEUE}
        celery.scaleml.autoscaler/broker: ${BROKER_NAME}
        celery.scaleml.autoscaler/taskVisibility: "VISIBILITY_24H"
        celery.scaleml.autoscaler/perWorker: "${PER_WORKER}"
        celery.scaleml.autoscaler/minWorkers: "${MIN_WORKERS}"
        celery.scaleml.autoscaler/maxWorkers: "${MAX_WORKERS}"
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            sidecar.istio.io/inject: "false"  # TODO: switch to scuttle
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: celery-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.celery_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --queue
                - "${QUEUE}"
                - --task-visibility
                - "VISIBILITY_24H"
                - --set
                - "forwarder.model.args.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.model.args.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --num-workers
                - "${PER_WORKER}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: CELERY_QUEUE
                  value: "${QUEUE}"
                - name: CELERY_TASK_VISIBILITY
                  value: "VISIBILITY_24H"
                - name: S3_BUCKET
                  value: "${CELERY_S3_BUCKET}"
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-triton-enhanced-runnable-image-sync-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${PER_WORKER}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: tritonserver
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/std-ml-srv:${TRITON_COMMIT_TAG}-triton
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - bash
                - -c
                - "$TRITON_COMMAND"
              env:
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
              ports:
                - containerPort: 8000
                  name: http
                - containerPort: 8001
                  name: grpc
                - containerPort: 8002
                  name: metrics
              readinessProbe:
                httpGet:
                # Need to have Triton support --http-address IPv6 :(
                # https://github:com/triton-inference-server/server/issues/5305:
                #   path: /v2/health/ready
                #   port: 8000
                  path: /readyz
                  port: 3000
                initialDelaySeconds: $TRITON_READINESS_INITIAL_DELAY
                periodSeconds: 10
              resources:
                requests:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
                limits:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-sync-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${PER_WORKER}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-streaming-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            node-lifecycle: normal
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - ddtrace-run
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/service--http_forwarder.yaml
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${PER_WORKER}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.stream.predict_route=${STREAMING_PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DATADOG_TRACE_ENABLED
                  value: "${DATADOG_TRACE_ENABLED}"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                # LIRA: For compatibility with runnable image converted from artifactlike bundle
                - name: config-volume
                  mountPath: /home/modelengine/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config  
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  user-config.yaml: |-
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    data:
      raw_data: ${CONFIG_DATA_SERIALIZED}
  endpoint-config.yaml: |-
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: ${RESOURCE_NAME}-endpoint-config
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    data:
      raw_data: ${ENDPOINT_CONFIG_SERIALIZED}
  horizontal-pod-autoscaler.yaml: |-
    apiVersion: ${API_VERSION}
    kind: HorizontalPodAutoscaler
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      minReplicas: ${MIN_WORKERS}
      maxReplicas: ${MAX_WORKERS}
      scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: ${RESOURCE_NAME}
      metrics:
        - type: Pods
          pods:
            metric:
              name: request-concurrency-average
            target:
              type: Value
              averageValue: ${CONCURRENCY}
  keda-scaled-object.yaml: |-
    apiVersion: keda.sh/v1alpha1
    kind: ScaledObject
    metadata:
      name: ${RESOURCE_NAME} 
      namespace: ${NAMESPACE} 
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      scaleTargetRef:
        name: ${RESOURCE_NAME}
      pollingInterval:  5
      cooldownPeriod:   300
      minReplicaCount:  ${MIN_WORKERS}
      maxReplicaCount:  ${MAX_WORKERS}
      fallback:
        failureThreshold: 3
        replicas: ${MIN_WORKERS}
      triggers:
      - type: redis
        metadata:
          address: ${REDIS_HOST_PORT} # Format must be host:port
          passwordFromEnv: ""
          listName: "launch-endpoint-autoscaling:${ENDPOINT_ID}"
          listLength: "100" # something absurdly high so we don't scale past 1 pod
          activationListLength: "0"
          enableTLS: "false"
          unsafeSsl: "false"
          databaseIndex: "${REDIS_DB_INDEX}"
  service.yaml: |-
    apiVersion: v1
    kind: Service
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      type: ${SERVICE_TYPE}
      selector:
        app: ${RESOURCE_NAME}
      ports:
        - port: 80
          targetPort: ${SERVICE_TARGET_PORT}
          protocol: TCP
          name: http
          ${NODE_PORT_DICT}
  virtual-service.yaml: |-
    apiVersion: networking.istio.io/v1alpha3
    kind: VirtualService
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      hosts:
        - ${RESOURCE_NAME}.${DNS_HOST_DOMAIN}
      gateways:
        - default/internal-gateway
      http:
        - route:
            - destination:
                host: "${RESOURCE_NAME}.${NAMESPACE}.svc.cluster.local"
                port:
                  number: 80
  destination-rule.yaml: |-
    apiVersion: networking.istio.io/v1beta1
    kind: DestinationRule
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      host: "${RESOURCE_NAME}.${NAMESPACE}.svc.cluster.local"
      trafficPolicy:
        loadBalancer:
          simple: LEAST_REQUEST
  vertical-pod-autoscaler.yaml: |-
    apiVersion: "autoscaling.k8s.io/v1"
    kind: VerticalPodAutoscaler
    metadata:
      name: ${RESOURCE_NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      targetRef:
        apiVersion: "apps/v1"
        kind: Deployment
        name: ${RESOURCE_NAME}
      updatePolicy:
        updateMode: "Auto"
      resourcePolicy:
        containerPolicies:
          - containerName: istio-proxy
            mode: "Off"
          - containerName: main
            minAllowed:
              cpu: 100m
              memory: 128Mi
            maxAllowed:
              cpu: ${CPUS}
              memory: ${MEMORY}
            controlledResources: ["cpu", "memory"]
  batch-job-orchestration-job.yaml: |-
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: ${RESOURCE_NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        launch_job_id: ${JOB_ID}
        tags.datadoghq.com/service: ${JOB_ID}
    spec:
      backoffLimit: 0
      activeDeadlineSeconds: ${BATCH_JOB_MAX_RUNTIME}
      ttlSecondsAfterFinished: ${BATCH_JOB_TTL_SECONDS_AFTER_FINISHED}
      template:
        metadata:
          labels:
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            launch_job_id: ${JOB_ID}
            tags.datadoghq.com/service: ${JOB_ID}
            sidecar.istio.io/inject: "false"
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"source": "python", "service": "${RESOURCE_NAME}", "tags": ["env:circleci", "launch_job_id:${JOB_ID}"]}]'
            cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        spec:
          restartPolicy: Never
          nodeSelector:
            node-lifecycle: normal
          serviceAccountName: model-engine
          volumes:
            - name: config-volume
              configMap:
                name: default-config
          containers:
            - name: main
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              env:
                - name: DD_SERVICE
                  value: ${RESOURCE_NAME}
                - name: DATADOG_TRACE_ENABLED
                  value: "false"
                - name: DD_ENV
                  value: circleci
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: SERVICE_IDENTIFIER
                - name: GATEWAY_URL
                  value: http://model-engine.default:80
                - name: AWS_PROFILE
                  value: default
                - name: ECR_READ_AWS_PROFILE
                  value: default
                - name: S3_WRITE_AWS_PROFILE
                  value: default
                - name: DB_SECRET_NAME
                  value: prod/ml_infra_pg
                - name: DEPLOY_SERVICE_CONFIG_PATH
                  value: /workspace/model-engine/service_configs/service_config.yaml
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: /workspace/model-engine/model_engine_server/core/configs/config.yaml
                - name: CELERY_ELASTICACHE_ENABLED
                  value: "true"
                - name: LAUNCH_SERVICE_TEMPLATE_FOLDER
                  value: /workspace/model-engine/model_engine_server/infra/gateways/resources/templates
                - name: CIRCLECI
                  value: ${CIRCLECI}
                - name: DD_VERSION
                  value: ${GIT_TAG}
                - name: GIT_TAG
                  value: ${GIT_TAG}
              imagePullPolicy: Always
              command:
                - dumb-init
                - --
                - ddtrace-run
              args:
                - python
                - -m
                - model_engine_server.entrypoints.start_batch_job_orchestration
                - --job-id
                - ${JOB_ID}
                - --owner
                - ${OWNER}
                - --input-path
                - ${INPUT_LOCATION}
                - --serialization-format
                - ${SERIALIZATION_FORMAT}
                - --timeout-seconds
                - "${BATCH_JOB_TIMEOUT}"
              resources:
                # If job pods get evicted, then we can make "Guaranteed QoS" by setting requests = limits.
                requests:
                  cpu: 1
                  memory: 8Gi
                limits:
                  cpu: 4
                  memory: 32Gi
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
  docker-image-batch-job-cpu.yaml: |-
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: ${RESOURCE_NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        launch_job_id: ${JOB_ID}
        tags.datadoghq.com/service: ${JOB_ID}
    spec:
      backoffLimit: 0
      activeDeadlineSeconds: ${BATCH_JOB_MAX_RUNTIME}
      ttlSecondsAfterFinished: ${BATCH_JOB_TTL_SECONDS_AFTER_FINISHED}
      template:
        metadata:
          labels:
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            launch_job_id: ${JOB_ID}
            tags.datadoghq.com/service: ${JOB_ID}
            sidecar.istio.io/inject: "false"
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"source": "python", "service": "${RESOURCE_NAME}", "tags": ["env:circleci", "launch_job_id:${JOB_ID}"]}]'
        spec:
          restartPolicy: Never
          nodeSelector:
            node-lifecycle: normal
          serviceAccountName: default
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: workdir
              emptyDir: {}
            - name: dshm
              emptyDir:
                medium: Memory
          containers:
            - name: main
              image: ${IMAGE}
              env:
                - name: DD_SERVICE
                  value: ${RESOURCE_NAME}
                - name: DATADOG_TRACE_ENABLED
                  value: "false"
                - name: DD_ENV
                  value: circleci
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: SERVICE_IDENTIFIER
                - name: GATEWAY_URL
                  value: http://model-engine.default:80
                - name: AWS_PROFILE
                  value: default
                - name: ECR_READ_AWS_PROFILE
                  value: default
                - name: S3_WRITE_AWS_PROFILE
                  value: default
                - name: DB_SECRET_NAME
                  value: prod/ml_infra_pg
                - name: DEPLOY_SERVICE_CONFIG_PATH
                  value: /workspace/model-engine/service_configs/service_config.yaml
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: /workspace/model-engine/model_engine_server/core/configs/config.yaml
                - name: CELERY_ELASTICACHE_ENABLED
                  value: "true"
                - name: LAUNCH_SERVICE_TEMPLATE_FOLDER
                  value: /workspace/model-engine/model_engine_server/infra/gateways/resources/templates
                - name: CIRCLECI
                  value: ${CIRCLECI}
                - name: DD_VERSION
                  value: ${GIT_TAG}
                - name: GIT_TAG
                  value: ${GIT_TAG}
              imagePullPolicy: Always
              command: ${COMMAND}
              resources:
                # If job pods get evicted, then we can make "Guaranteed QoS" by setting requests = limits.
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: workdir
                  mountPath: ${MOUNT_PATH}
                - mountPath: /dev/shm
                  name: dshm
          initContainers:
            - name: input-downloader
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              command:
                - python
                - -m
                - model_engine_server.entrypoints.start_docker_image_batch_job_init_container
                - ${INPUT_LOCATION}
                - --remote-file
                - ${S3_FILE}
                - --local-file
                - ${LOCAL_FILE_NAME}
                - --file-contents-b64encoded
                - ${FILE_CONTENTS_B64ENCODED}
              resources:
                requests:
                  cpu: 1
                  memory: 1Gi
                limits:
                  cpu: 1
                  memory: 1Gi
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: workdir
                  mountPath: ${MOUNT_PATH}
  docker-image-batch-job-gpu.yaml: |-
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: ${RESOURCE_NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        launch_job_id: ${JOB_ID}
        tags.datadoghq.com/service: ${JOB_ID}
    spec:
      backoffLimit: 0
      activeDeadlineSeconds: ${BATCH_JOB_MAX_RUNTIME}
      ttlSecondsAfterFinished: ${BATCH_JOB_TTL_SECONDS_AFTER_FINISHED}
      template:
        metadata:
          labels:
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            launch_job_id: ${JOB_ID}
            tags.datadoghq.com/service: ${JOB_ID}
            sidecar.istio.io/inject: "false"
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"source": "python", "service": "${RESOURCE_NAME}", "tags": ["env:circleci", "launch_job_id:${JOB_ID}"]}]'
        spec:
          restartPolicy: Never
          nodeSelector:
            node-lifecycle: normal
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          serviceAccountName: default
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: workdir
              emptyDir: {}
            - name: dshm
              emptyDir:
                medium: Memory
          containers:
            - name: main
              image: ${IMAGE}
              env:
                - name: DD_SERVICE
                  value: ${RESOURCE_NAME}
                - name: DATADOG_TRACE_ENABLED
                  value: "false"
                - name: DD_ENV
                  value: circleci
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: SERVICE_IDENTIFIER
                - name: GATEWAY_URL
                  value: http://model-engine.default:80
                - name: AWS_PROFILE
                  value: default
                - name: ECR_READ_AWS_PROFILE
                  value: default
                - name: S3_WRITE_AWS_PROFILE
                  value: default
                - name: DB_SECRET_NAME
                  value: prod/ml_infra_pg
                - name: DEPLOY_SERVICE_CONFIG_PATH
                  value: /workspace/model-engine/service_configs/service_config.yaml
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: /workspace/model-engine/model_engine_server/core/configs/config.yaml
                - name: CELERY_ELASTICACHE_ENABLED
                  value: "true"
                - name: LAUNCH_SERVICE_TEMPLATE_FOLDER
                  value: /workspace/model-engine/model_engine_server/infra/gateways/resources/templates
                - name: CIRCLECI
                  value: ${CIRCLECI}
                - name: DD_VERSION
                  value: ${GIT_TAG}
                - name: GIT_TAG
                  value: ${GIT_TAG}
              imagePullPolicy: Always
              command: ${COMMAND}
              resources:
                # If job pods get evicted, then we can make "Guaranteed QoS" by setting requests = limits.
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: workdir
                  mountPath: ${MOUNT_PATH}
                - mountPath: /dev/shm
                  name: dshm
          initContainers:
            - name: input-downloader
              image: 000000000000.dkr.ecr.us-west-2.amazonaws.com/model-engine:${GIT_TAG}
              command:
                - python
                - -m
                - model_engine_server.entrypoints.start_docker_image_batch_job_init_container
                - ${INPUT_LOCATION}
                - --remote-file
                - ${S3_FILE}
                - --local-file
                - ${LOCAL_FILE_NAME}
                - --file-contents-b64encoded
                - ${FILE_CONTENTS_B64ENCODED}
              resources:
                requests:
                  cpu: 1
                  memory: 1Gi
                limits:
                  cpu: 1
                  memory: 1Gi
              volumeMounts:
                - name: config-volume
                  mountPath: /root/.aws/config
                  subPath: config
                - name: workdir
                  mountPath: ${MOUNT_PATH}
  image-cache-cpu.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            cpu-only: "true"
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  image-cache-a10.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            k8s.amazonaws.com/accelerator: nvidia-ampere-a10
          tolerations:
            - effect: NoSchedule
              key: nvidia.com/gpu
              operator: Exists
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  image-cache-a100.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            k8s.amazonaws.com/accelerator: nvidia-ampere-a100
          tolerations:
            - effect: NoSchedule
              key: nvidia.com/gpu
              operator: Exists
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  image-cache-t4.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            k8s.amazonaws.com/accelerator: nvidia-tesla-t4
          tolerations:
            - effect: NoSchedule
              key: nvidia.com/gpu
              operator: Exists
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  cron-trigger.yaml: |-
    apiVersion: batch/v1
    kind: CronJob
    metadata:
      name: ${NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        launch_trigger_id: ${TRIGGER_ID}
        tags.datadoghq.com/service: ${TRIGGER_ID}
    spec:
      schedule: "${CRON_SCHEDULE}"
      successfulJobsHistoryLimit: 0
      failedJobsHistoryLimit: 0
      jobTemplate:
        spec:
          backoffLimit: 0
          activeDeadlineSeconds: ${BATCH_CURL_JOB_ACTIVE_DEADLINE_SECONDS}
          template:
            metadata:
              labels:
                user_id: ${OWNER}
                team: ${TEAM}
                product: ${PRODUCT}
                created_by: ${CREATED_BY}
                owner: ${OWNER}
                launch_trigger_id: ${TRIGGER_ID}
                tags.datadoghq.com/service: ${TRIGGER_ID}
            spec:
              containers:
              - name: ${NAME}
                image: curlimages/curl:7.72.0
                imagePullPolicy: IfNotPresent
                command:
                - curl
                - -X
                - 'POST'
                - '${HOST}/v1/docker-image-batch-jobs'
                - -H
                - 'accept: application/json'
                - -H
                - 'Content-Type: application/json'
                - -d
                - '{ "docker_image_batch_job_bundle_id": "${DOCKER_IMAGE_BATCH_JOB_BUNDLE_ID}", "job_config": ${JOB_CONFIG}, "labels": ${JOB_METADATA}  }'
                - -u
                - '${OWNER}:'
              restartPolicy: Never
