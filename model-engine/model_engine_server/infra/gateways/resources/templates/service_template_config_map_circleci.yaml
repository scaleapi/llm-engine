---
# Source: model-engine/templates/service_template_config_map.yaml
# THIS FILE IS AUTOGENERATED USING `just autogen-templates`. PLEASE EDIT THE GOTEMPLATE FILE IN THE HELM CHART!!!
apiVersion: v1
kind: ConfigMap
metadata:
  name: model-engine-service-template-config
  labels:
    team: infra
    app.kubernetes.io/version: 2eed5f3c60f2b33784877a07b01cbbafee472272
    tags.datadoghq.com/version: 2eed5f3c60f2b33784877a07b01cbbafee472272
    tags.datadoghq.com/env: circleci
    env: circleci
    product: model-engine
    helm.sh/chart: model-engine-0.1.6
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-2"
data:
  deployment-triton-enhanced-runnable-image-async-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
      annotations:
        celery.scaleml.autoscaler/queue: ${QUEUE}
        celery.scaleml.autoscaler/broker: ${BROKER_NAME}
        celery.scaleml.autoscaler/taskVisibility: "VISIBILITY_24H"
        celery.scaleml.autoscaler/perWorker: "${PER_WORKER}"
        celery.scaleml.autoscaler/minWorkers: "${MIN_WORKERS}"
        celery.scaleml.autoscaler/maxWorkers: "${MAX_WORKERS}"
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            sidecar.istio.io/inject: "false"  # TODO: switch to scuttle
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 1800
          serviceAccount: default
          priorityClassName: ${PRIORITY}
          containers:
            - name: celery-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.celery_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --queue
                - "${QUEUE}"
                - --task-visibility
                - "VISIBILITY_24H"
                - --set
                - "forwarder.async.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.async.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --num-workers
                - "${CONCURRENT_REQUESTS_PER_WORKER}"
                - --broker-type
                - redis
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: CELERY_QUEUE
                  value: "${QUEUE}"
                - name: CELERY_TASK_VISIBILITY
                  value: "VISIBILITY_24H"
                - name: S3_BUCKET
                  value: "${CELERY_S3_BUCKET}"
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
            - name: tritonserver
              image: nvidia/tritonserver:${TRITON_COMMIT_TAG}-triton
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - bash
                - -c
                - "$TRITON_COMMAND"
              env:
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
              ports:
                - containerPort: 8000
                  name: http
                - containerPort: 8001
                  name: grpc
                - containerPort: 8002
                  name: metrics
              readinessProbe:
                httpGet:
                # Need to have Triton support --http-address IPv6 :(
                # https://github:com/triton-inference-server/server/issues/5305:
                #   path: /v2/health/ready
                #   port: 8000
                  path: /readyz
                  port: 3000
                initialDelaySeconds: $TRITON_READINESS_INITIAL_DELAY
                periodSeconds: 10
              resources:
                requests:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
                limits:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-async-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
      annotations:
        celery.scaleml.autoscaler/queue: ${QUEUE}
        celery.scaleml.autoscaler/broker: ${BROKER_NAME}
        celery.scaleml.autoscaler/taskVisibility: "VISIBILITY_24H"
        celery.scaleml.autoscaler/perWorker: "${PER_WORKER}"
        celery.scaleml.autoscaler/minWorkers: "${MIN_WORKERS}"
        celery.scaleml.autoscaler/maxWorkers: "${MAX_WORKERS}"
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            sidecar.istio.io/inject: "false"  # TODO: switch to scuttle
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 1800
          serviceAccount: default
          priorityClassName: ${PRIORITY}
          containers:
            - name: celery-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.celery_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --queue
                - "${QUEUE}"
                - --task-visibility
                - "VISIBILITY_24H"
                - --set
                - "forwarder.async.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.async.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --num-workers
                - "${CONCURRENT_REQUESTS_PER_WORKER}"
                - --broker-type
                - redis
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: CELERY_QUEUE
                  value: "${QUEUE}"
                - name: CELERY_TASK_VISIBILITY
                  value: "VISIBILITY_24H"
                - name: S3_BUCKET
                  value: "${CELERY_S3_BUCKET}"
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-triton-enhanced-runnable-image-sync-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${FORWARDER_WORKER_COUNT}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: tritonserver
              image: nvidia/tritonserver:${TRITON_COMMIT_TAG}-triton
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - bash
                - -c
                - "$TRITON_COMMAND"
              env:
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
              ports:
                - containerPort: 8000
                  name: http
                - containerPort: 8001
                  name: grpc
                - containerPort: 8002
                  name: metrics
              readinessProbe:
                httpGet:
                # Need to have Triton support --http-address IPv6 :(
                # https://github:com/triton-inference-server/server/issues/5305:
                #   path: /v2/health/ready
                #   port: 8000
                  path: /readyz
                  port: 3000
                initialDelaySeconds: $TRITON_READINESS_INITIAL_DELAY
                periodSeconds: 10
              resources:
                requests:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
                limits:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-sync-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${FORWARDER_WORKER_COUNT}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-streaming-cpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/service--http_forwarder.yaml
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${FORWARDER_WORKER_COUNT}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.stream.predict_route=${STREAMING_PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.sync.extra_routes=${FORWARDER_EXTRA_ROUTES}"
                - --set
                - "forwarder.stream.extra_routes=${FORWARDER_EXTRA_ROUTES}"
                - --set
                - "forwarder.sync.forwarder_type=${FORWARDER_TYPE}"
                - --set
                - "forwarder.stream.forwarder_type=${FORWARDER_TYPE}"
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-triton-enhanced-runnable-image-async-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
      annotations:
        celery.scaleml.autoscaler/queue: ${QUEUE}
        celery.scaleml.autoscaler/broker: ${BROKER_NAME}
        celery.scaleml.autoscaler/taskVisibility: "VISIBILITY_24H"
        celery.scaleml.autoscaler/perWorker: "${PER_WORKER}"
        celery.scaleml.autoscaler/minWorkers: "${MIN_WORKERS}"
        celery.scaleml.autoscaler/maxWorkers: "${MAX_WORKERS}"
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            sidecar.istio.io/inject: "false"  # TODO: switch to scuttle
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 1800
          serviceAccount: default
          nodeSelector:
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: celery-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.celery_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --queue
                - "${QUEUE}"
                - --task-visibility
                - "VISIBILITY_24H"
                - --set
                - "forwarder.async.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.async.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --num-workers
                - "${CONCURRENT_REQUESTS_PER_WORKER}"
                - --broker-type
                - redis
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: CELERY_QUEUE
                  value: "${QUEUE}"
                - name: CELERY_TASK_VISIBILITY
                  value: "VISIBILITY_24H"
                - name: S3_BUCKET
                  value: "${CELERY_S3_BUCKET}"
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
            - name: tritonserver
              image: nvidia/tritonserver:${TRITON_COMMIT_TAG}-triton
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - bash
                - -c
                - "$TRITON_COMMAND"
              env:
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
              ports:
                - containerPort: 8000
                  name: http
                - containerPort: 8001
                  name: grpc
                - containerPort: 8002
                  name: metrics
              readinessProbe:
                httpGet:
                # Need to have Triton support --http-address IPv6 :(
                # https://github:com/triton-inference-server/server/issues/5305:
                #   path: /v2/health/ready
                #   port: 8000
                  path: /readyz
                  port: 3000
                initialDelaySeconds: $TRITON_READINESS_INITIAL_DELAY
                periodSeconds: 10
              resources:
                requests:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
                limits:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-async-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
      annotations:
        celery.scaleml.autoscaler/queue: ${QUEUE}
        celery.scaleml.autoscaler/broker: ${BROKER_NAME}
        celery.scaleml.autoscaler/taskVisibility: "VISIBILITY_24H"
        celery.scaleml.autoscaler/perWorker: "${PER_WORKER}"
        celery.scaleml.autoscaler/minWorkers: "${MIN_WORKERS}"
        celery.scaleml.autoscaler/maxWorkers: "${MAX_WORKERS}"
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            sidecar.istio.io/inject: "false"  # TODO: switch to scuttle
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 1800
          serviceAccount: default
          nodeSelector:
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: celery-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.celery_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --queue
                - "${QUEUE}"
                - --task-visibility
                - "VISIBILITY_24H"
                - --set
                - "forwarder.async.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.async.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --num-workers
                - "${CONCURRENT_REQUESTS_PER_WORKER}"
                - --broker-type
                - redis
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: CELERY_QUEUE
                  value: "${QUEUE}"
                - name: CELERY_TASK_VISIBILITY
                  value: "VISIBILITY_24H"
                - name: S3_BUCKET
                  value: "${CELERY_S3_BUCKET}"
              resources:
                requests:
                  cpu: 0.1
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-triton-enhanced-runnable-image-sync-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${FORWARDER_WORKER_COUNT}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: tritonserver
              image: nvidia/tritonserver:${TRITON_COMMIT_TAG}-triton
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - bash
                - -c
                - "$TRITON_COMMAND"
              env:
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
              ports:
                - containerPort: 8000
                  name: http
                - containerPort: 8001
                  name: grpc
                - containerPort: 8002
                  name: metrics
              readinessProbe:
                httpGet:
                # Need to have Triton support --http-address IPv6 :(
                # https://github:com/triton-inference-server/server/issues/5305:
                #   path: /v2/health/ready
                #   port: 8000
                  path: /readyz
                  port: 3000
                initialDelaySeconds: $TRITON_READINESS_INITIAL_DELAY
                periodSeconds: 10
              resources:
                requests:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
                limits:
                  cpu: ${TRITON_CPUS}
                  ${TRITON_MEMORY_DICT}
                  ${TRITON_STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-sync-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/${FORWARDER_CONFIG_FILE_NAME}
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${FORWARDER_WORKER_COUNT}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  deployment-runnable-image-streaming-gpu.yaml: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      replicas: ${MIN_WORKERS}
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            tags.datadoghq.com/service: ${ENDPOINT_NAME}
            endpoint_id: ${ENDPOINT_ID}
            endpoint_name: ${ENDPOINT_NAME}
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
            kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
        spec:
          affinity:
            podAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 1
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - ${RESOURCE_NAME}
                  topologyKey: kubernetes.io/hostname
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: ${IMAGE_HASH}
                      operator: In
                      values:
                      - "True"
                  topologyKey: kubernetes.io/hostname
          terminationGracePeriodSeconds: 600
          serviceAccount: default
          nodeSelector:
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          priorityClassName: ${PRIORITY}
          containers:
            - name: http-forwarder
              image: model-engine:${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - /usr/bin/dumb-init
                - --
                - python
                - -m
                - model_engine_server.inference.forwarding.http_forwarder
                - --config
                - /workspace/model-engine/model_engine_server/inference/configs/service--http_forwarder.yaml
                - --port
                - "${FORWARDER_PORT}"
                - --num-workers
                - "${FORWARDER_WORKER_COUNT}"
                - --set
                - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                - --set
                - "forwarder.stream.predict_route=${STREAMING_PREDICT_ROUTE}"
                - --set
                - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
                - --set
                - "forwarder.sync.extra_routes=${FORWARDER_EXTRA_ROUTES}"
                - --set
                - "forwarder.stream.extra_routes=${FORWARDER_EXTRA_ROUTES}"
                - --set
                - "forwarder.sync.forwarder_type=${FORWARDER_TYPE}"
                - --set
                - "forwarder.stream.forwarder_type=${FORWARDER_TYPE}"
              env:
                - name: DD_TRACE_ENABLED
                  value: "${DD_TRACE_ENABLED}"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_SERVICE
                  value: "${ENDPOINT_NAME}"
                - name: DD_ENV
                  value: circleci
                - name: DD_VERSION
                  value: "${GIT_TAG}"
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: AWS_PROFILE
                  value: "${AWS_ROLE}"
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: RESULTS_S3_BUCKET
                  value: "${RESULTS_S3_BUCKET}"
                - name: BASE_PATH
                  value: "/workspace"
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                - name: HTTP_HOST
                  value: "0.0.0.0"
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: ${FORWARDER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: "100M"
                  ephemeral-storage: "100M"
                limits:
                  cpu: ${FORWARDER_CPUS_LIMIT}
                  memory: ${FORWARDER_MEMORY_LIMIT}
                  ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
              
              
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: user-config
                  mountPath: /workspace/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /workspace/endpoint_config
                  subPath: raw_data
                - name: infra-service-config-volume
                  mountPath: /workspace/model-engine/model_engine_server/core/configs
              ports:
                - containerPort: ${FORWARDER_PORT}
                  name: http
            - name: main
              securityContext:
                capabilities:
                  drop:
                  - all
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              env: ${MAIN_ENV}
              readinessProbe:
                httpGet:
                  path: ${HEALTHCHECK_ROUTE}
                  port: ${USER_CONTAINER_PORT}
                initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                periodSeconds: 5
                timeoutSeconds: 5
              resources:
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - mountPath: /dev/shm
                  name: dshm
                - name: infra-service-config-volume
                  mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                - name: user-config
                  mountPath: /app/user_config
                  subPath: raw_data
                - name: endpoint-config
                  mountPath: /app/endpoint_config
                  subPath: raw_data
              ports:
                - containerPort: ${USER_CONTAINER_PORT}
                  name: http
          # Workaround for https://github.com/kubernetes-sigs/external-dns/pull/1185
          securityContext:
            fsGroup: 65534
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: user-config
              configMap:
                name: ${RESOURCE_NAME}
            - name: endpoint-config
              configMap:
                name: ${RESOURCE_NAME}-endpoint-config
            - name: dshm
              emptyDir:
                medium: Memory
            - name: infra-service-config-volume
              configMap:
                name: model-engine-service-config
                items:
                  - key: infra_service_config
                    path: config.yaml
  user-config.yaml: |-
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    data:
      raw_data: ${CONFIG_DATA_SERIALIZED}
  endpoint-config.yaml: |-
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: ${RESOURCE_NAME}-endpoint-config
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    data:
      raw_data: ${ENDPOINT_CONFIG_SERIALIZED}
  horizontal-pod-autoscaler.yaml: |-
    apiVersion: ${API_VERSION}
    kind: HorizontalPodAutoscaler
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      minReplicas: ${MIN_WORKERS}
      maxReplicas: ${MAX_WORKERS}
      scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: ${RESOURCE_NAME}
      metrics:
        - type: Pods
          pods:
            metric:
              name: request-concurrency-average
            target:
              type: Value
              averageValue: ${CONCURRENCY}
  keda-scaled-object.yaml: |-
    apiVersion: keda.sh/v1alpha1
    kind: ScaledObject
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      scaleTargetRef:
        name: ${RESOURCE_NAME}
      pollingInterval:  5
      cooldownPeriod:   300
      minReplicaCount:  ${MIN_WORKERS}
      maxReplicaCount:  ${MAX_WORKERS}
      fallback:
        failureThreshold: 3
        replicas: ${MIN_WORKERS}
      triggers:
      - type: redis
        metadata:
          address: ${REDIS_HOST_PORT} # Format must be host:port
          passwordFromEnv: ""
          listName: "launch-endpoint-autoscaling:${ENDPOINT_ID}"
          listLength: "100" # something absurdly high so we don't scale past 1 pod
          activationListLength: "0"
          enableTLS: "false"
          unsafeSsl: "false"
          databaseIndex: "${REDIS_DB_INDEX}"
      - type: prometheus
        metadata:
          threshold: "${CONCURRENCY}"
          metricName: request_concurrency_average
          query: sum(rate(istio_request_duration_milliseconds_sum{destination_workload="${RESOURCE_NAME}"}[2m])) / 1000
          serverAddress: ${PROMETHEUS_SERVER_ADDRESS}
  leader-worker-set-streaming-gpu.yaml: |-
    apiVersion: leaderworkerset.x-k8s.io/v1
    kind: LeaderWorkerSet
    metadata:
      name: ${RESOURCE_NAME} 
      namespace: ${NAMESPACE} 
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      replicas: ${MIN_WORKERS}
      leaderWorkerTemplate:
        size: ${LWS_SIZE}
        restartPolicy: RecreateGroupOnPodRestart  # TODO un-hardcode? if necessary
        leaderTemplate:
          metadata:
            labels:
              app: ${RESOURCE_NAME}
              role: leader
              user_id: ${OWNER}
              team: ${TEAM}
              product: ${PRODUCT}
              created_by: ${CREATED_BY}
              owner: ${OWNER}
              env: circleci
              managed-by: model-engine
              use_scale_launch_endpoint_network_policy: "true"
              tags.datadoghq.com/env: circleci
              tags.datadoghq.com/version: ${GIT_TAG}
              tags.datadoghq.com/service: ${ENDPOINT_NAME}
              endpoint_id: ${ENDPOINT_ID}
              endpoint_name: ${ENDPOINT_NAME}
              sidecar.istio.io/inject: "false"  # Never inject istio, it screws up networking
              version: v1
            annotations:
              ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
              kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
          spec:
            affinity:
              podAffinity:
                preferredDuringSchedulingIgnoredDuringExecution:
                - weight: 1
                  podAffinityTerm:
                    labelSelector:
                      matchExpressions:
                      - key: app
                        operator: In
                        values:
                        - ${RESOURCE_NAME}
                    topologyKey: kubernetes.io/hostname
                - weight: 100
                  podAffinityTerm:
                    labelSelector:
                      matchExpressions:
                      - key: ${IMAGE_HASH}
                        operator: In
                        values:
                        - "True"
                    topologyKey: kubernetes.io/hostname
            terminationGracePeriodSeconds: 600
            serviceAccount: default
            nodeSelector:
              k8s.amazonaws.com/accelerator: ${GPU_TYPE}
            tolerations:
              - key: "nvidia.com/gpu"
                operator: "Exists"
                effect: "NoSchedule"
            priorityClassName: ${PRIORITY}
            containers:
              - name: http-forwarder
                image: model-engine:${GIT_TAG}
                imagePullPolicy: IfNotPresent
                command:
                  - /usr/bin/dumb-init
                  - --
                  - python
                  - -m
                  - model_engine_server.inference.forwarding.http_forwarder
                  - --config
                  - /workspace/model-engine/model_engine_server/inference/configs/service--http_forwarder.yaml
                  - --port
                  - "${FORWARDER_PORT}"
                  - --num-workers
                  - "${FORWARDER_WORKER_COUNT}"
                  - --set
                  - "forwarder.sync.predict_route=${PREDICT_ROUTE}"
                  - --set
                  - "forwarder.stream.predict_route=${STREAMING_PREDICT_ROUTE}"
                  - --set
                  - "forwarder.sync.healthcheck_route=${HEALTHCHECK_ROUTE}"
                  - --set
                  - "forwarder.stream.healthcheck_route=${HEALTHCHECK_ROUTE}"
                env:
                  - name: DD_TRACE_ENABLED
                    value: "${DD_TRACE_ENABLED}"
                  - name: DD_REMOTE_CONFIGURATION_ENABLED
                    value: "false"
                  - name: DD_SERVICE
                    value: "${ENDPOINT_NAME}"
                  - name: DD_ENV
                    value: circleci
                  - name: DD_VERSION
                    value: "${GIT_TAG}"
                  - name: DD_AGENT_HOST
                    valueFrom:
                      fieldRef:
                        fieldPath: status.hostIP
                  - name: AWS_PROFILE
                    value: "${AWS_ROLE}"
                  - name: AWS_CONFIG_FILE
                    value: /opt/.aws/config
                  - name: RESULTS_S3_BUCKET
                    value: "${RESULTS_S3_BUCKET}"
                  - name: BASE_PATH
                    value: "/workspace"
                  - name: ML_INFRA_SERVICES_CONFIG_PATH
                    value: "/workspace/model-engine/model_engine_server/core/configs/config.yaml"
                  - name: HTTP_HOST
                    value: "0.0.0.0"
                readinessProbe:
                  httpGet:
                    path: /readyz
                    port: ${FORWARDER_PORT}
                  initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                  periodSeconds: 5
                  timeoutSeconds: 5
                resources:
                  requests:
                    cpu: ${FORWARDER_CPUS_LIMIT}
                    memory: "100M"
                    ephemeral-storage: "100M"
                  limits:
                    cpu: ${FORWARDER_CPUS_LIMIT}
                    memory: ${FORWARDER_MEMORY_LIMIT}
                    ephemeral-storage: ${FORWARDER_STORAGE_LIMIT}
                
                
                volumeMounts:
                  - name: config-volume
                    mountPath: /opt/.aws/config
                    subPath: config
                  - name: user-config
                    mountPath: /workspace/user_config
                    subPath: raw_data
                  - name: endpoint-config
                    mountPath: /workspace/endpoint_config
                    subPath: raw_data
                  - name: infra-service-config-volume
                    mountPath: /workspace/model-engine/model_engine_server/core/configs
                ports:
                  - containerPort: ${FORWARDER_PORT}
                    name: http
              - name: lws-leader
                image: ${IMAGE}
                imagePullPolicy: IfNotPresent
                command: ${COMMAND}
                env: ${MAIN_ENV}
                readinessProbe:
                  httpGet:
                    path: ${HEALTHCHECK_ROUTE}
                    port: ${USER_CONTAINER_PORT}
                  initialDelaySeconds: ${READINESS_INITIAL_DELAY}
                  periodSeconds: 5
                  timeoutSeconds: 5
                resources:
                  requests:
                    nvidia.com/gpu: ${GPUS}
                    cpu: ${CPUS}
                    memory: ${MEMORY}
                    ${STORAGE_DICT}
                  limits:
                    nvidia.com/gpu: ${GPUS}
                    cpu: ${CPUS}
                    memory: ${MEMORY}
                    ${STORAGE_DICT}
                volumeMounts:
                  - name: config-volume
                    mountPath: /opt/.aws/config
                    subPath: config
                  - mountPath: /dev/shm
                    name: dshm
                  - name: infra-service-config-volume
                    mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                  - name: user-config
                    mountPath: /app/user_config
                    subPath: raw_data
                  - name: endpoint-config
                    mountPath: /app/endpoint_config
                    subPath: raw_data
                ports:
                  - containerPort: ${USER_CONTAINER_PORT}
                    name: http
            volumes:
              - name: config-volume
                configMap:
                  name: default-config
              - name: user-config
                configMap:
                  name: ${RESOURCE_NAME}
              - name: endpoint-config
                configMap:
                  name: ${RESOURCE_NAME}-endpoint-config
              - name: dshm
                emptyDir:
                  medium: Memory
              - name: infra-service-config-volume
                configMap:
                  name: model-engine-service-config
                  items:
                    - key: infra_service_config
                      path: config.yaml
        workerTemplate:
          metadata:
            labels:
              app: ${RESOURCE_NAME}
              role: worker
              user_id: ${OWNER}
              team: ${TEAM}
              product: ${PRODUCT}
              created_by: ${CREATED_BY}
              owner: ${OWNER}
              env: circleci
              managed-by: model-engine
              use_scale_launch_endpoint_network_policy: "true"
              tags.datadoghq.com/env: circleci
              tags.datadoghq.com/version: ${GIT_TAG}
              tags.datadoghq.com/service: ${ENDPOINT_NAME}
              endpoint_id: ${ENDPOINT_ID}
              endpoint_name: ${ENDPOINT_NAME}
              sidecar.istio.io/inject: "false"  # Never inject istio for LWS, it screws up networking
              version: v1
            annotations:
              ad.datadoghq.com/main.logs: '[{"service": "${ENDPOINT_NAME}", "source": "python"}]'
              kubernetes.io/change-cause: "${CHANGE_CAUSE_MESSAGE}"
          spec:
            affinity:
              podAffinity:
                preferredDuringSchedulingIgnoredDuringExecution:
                - weight: 1
                  podAffinityTerm:
                    labelSelector:
                      matchExpressions:
                      - key: app
                        operator: In
                        values:
                        - ${RESOURCE_NAME}
                    topologyKey: kubernetes.io/hostname
                - weight: 100
                  podAffinityTerm:
                    labelSelector:
                      matchExpressions:
                      - key: ${IMAGE_HASH}
                        operator: In
                        values:
                        - "True"
                    topologyKey: kubernetes.io/hostname
            terminationGracePeriodSeconds: 600
            serviceAccount: default
            nodeSelector:
              k8s.amazonaws.com/accelerator: ${GPU_TYPE}
            tolerations:
              - key: "nvidia.com/gpu"
                operator: "Exists"
                effect: "NoSchedule"
            priorityClassName: ${PRIORITY}
            containers:
              - name: lws-worker
                image: ${IMAGE}
                imagePullPolicy: IfNotPresent
                command: ${WORKER_COMMAND}
                env: ${WORKER_ENV}
                resources:
                  requests:
                    nvidia.com/gpu: ${GPUS}
                    cpu: ${CPUS}
                    memory: ${MEMORY}
                    ${STORAGE_DICT}
                  limits:
                    nvidia.com/gpu: ${GPUS}
                    cpu: ${CPUS}
                    memory: ${MEMORY}
                    ${STORAGE_DICT}
                volumeMounts:
                  - name: config-volume
                    mountPath: /opt/.aws/config
                    subPath: config
                  - mountPath: /dev/shm
                    name: dshm
                  - name: infra-service-config-volume
                    mountPath: ${INFRA_SERVICE_CONFIG_VOLUME_MOUNT_PATH}
                  - name: user-config
                    mountPath: /app/user_config
                    subPath: raw_data
                  - name: endpoint-config
                    mountPath: /app/endpoint_config
                    subPath: raw_data
                ports:
                  - containerPort: ${USER_CONTAINER_PORT}
                    name: http
            volumes:
              - name: config-volume
                configMap:
                  name: default-config
              - name: user-config
                configMap:
                  name: ${RESOURCE_NAME}
              - name: endpoint-config
                configMap:
                  name: ${RESOURCE_NAME}-endpoint-config
              - name: dshm
                emptyDir:
                  medium: Memory
              - name: infra-service-config-volume
                configMap:
                  name: model-engine-service-config
                  items:
                    - key: infra_service_config
                      path: config.yaml  # mode  # device
  service.yaml: |-
    apiVersion: v1
    kind: Service
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      type: ${SERVICE_TYPE}
      selector:
        app: ${RESOURCE_NAME}
      ports:
        - port: 80
          targetPort: ${SERVICE_TARGET_PORT}
          protocol: TCP
          name: http
          ${NODE_PORT_DICT}
  lws-service.yaml: |-
    apiVersion: v1
    kind: Service
    metadata:
      name: ${SERVICE_NAME_OVERRIDE}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      type: ${SERVICE_TYPE}
      selector:
        app: ${RESOURCE_NAME}
        role: leader
      ports:
        - port: 80
          targetPort: ${SERVICE_TARGET_PORT}
          protocol: TCP
          name: http
          ${NODE_PORT_DICT}
  virtual-service.yaml: |-
    apiVersion: networking.istio.io/v1alpha3
    kind: VirtualService
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      hosts:
        - ${RESOURCE_NAME}.${DNS_HOST_DOMAIN}
      gateways:
        - default/internal-gateway
      http:
        - route:
            - destination:
                host: "${RESOURCE_NAME}.${NAMESPACE}.svc.cluster.local"
                port:
                  number: 80
  destination-rule.yaml: |-
    apiVersion: networking.istio.io/v1beta1
    kind: DestinationRule
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      host: "${RESOURCE_NAME}.${NAMESPACE}.svc.cluster.local"
      trafficPolicy:
        loadBalancer:
          simple: LEAST_REQUEST
  lws-service-entry.yaml: |-
    apiVersion: networking.istio.io/v1beta1
    kind: ServiceEntry
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      hosts:
      - "${SERVICE_NAME_OVERRIDE}.${NAMESPACE}.svc.cluster.local"
      location: MESH_EXTERNAL
      ports:
      - number: 80
        name: http
        protocol: HTTP
      resolution: NONE
  vertical-pod-autoscaler.yaml: |-
    apiVersion: "autoscaling.k8s.io/v1"
    kind: VerticalPodAutoscaler
    metadata:
      name: ${RESOURCE_NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      targetRef:
        apiVersion: "apps/v1"
        kind: Deployment
        name: ${RESOURCE_NAME}
      updatePolicy:
        updateMode: "Auto"
      resourcePolicy:
        containerPolicies:
          - containerName: istio-proxy
            mode: "Off"
          - containerName: main
            minAllowed:
              cpu: 100m
              memory: 128Mi
            maxAllowed:
              cpu: ${CPUS}
              memory: ${MEMORY}
            controlledResources: ["cpu", "memory"]
  pod-disruption-budget.yaml: |-
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        tags.datadoghq.com/service: ${ENDPOINT_NAME}
        endpoint_id: ${ENDPOINT_ID}
        endpoint_name: ${ENDPOINT_NAME}
    spec:
      maxUnavailable: 50%
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
  batch-job-orchestration-job.yaml: |-
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: ${RESOURCE_NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        launch_job_id: ${JOB_ID}
        tags.datadoghq.com/request_id: ${REQUEST_ID}
        tags.datadoghq.com/service: ${JOB_ID}
        tags.datadoghq.com/user_id: ${OWNER}
        tags.datadoghq.com/team: ${TEAM}
    spec:
      backoffLimit: 0
      activeDeadlineSeconds: ${BATCH_JOB_MAX_RUNTIME}
      ttlSecondsAfterFinished: ${BATCH_JOB_TTL_SECONDS_AFTER_FINISHED}
      template:
        metadata:
          labels:
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            launch_job_id: ${JOB_ID}
            tags.datadoghq.com/request_id: ${REQUEST_ID}
            tags.datadoghq.com/service: ${JOB_ID}
            tags.datadoghq.com/user_id: ${OWNER}
            tags.datadoghq.com/team: ${TEAM}
            sidecar.istio.io/inject: "false"
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"source": "python", "service": "${RESOURCE_NAME}", "tags": ["env:circleci", "launch_job_id:${JOB_ID}"]}]'
            cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        spec:
          restartPolicy: Never
          serviceAccountName: model-engine
          volumes:
            - name: config-volume
              configMap:
                name: default-config
          containers:
            - name: main
              image: model-engine:${GIT_TAG}
              env:
                - name: DD_SERVICE
                  value: ${RESOURCE_NAME}
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
                - name: DD_TRACE_ENABLED
                  value: "true"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_ENV
                  value: circleci
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: SERVICE_IDENTIFIER
                - name: GATEWAY_URL
                  value: http://model-engine.default:80
                - name: AWS_PROFILE
                  value: default
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: ECR_READ_AWS_PROFILE
                  value: default
                - name: DB_SECRET_AWS_PROFILE
                  value: default
                - name: S3_WRITE_AWS_PROFILE
                  value: default
                - name: ML_INFRA_DATABASE_URL
                  valueFrom:
                    secretKeyRef:
                      key: database_url
                      name: model-engine-postgres-credentials
                - name: DEPLOY_SERVICE_CONFIG_PATH
                  value: /workspace/model-engine/service_configs/service_config.yaml
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: /workspace/model-engine/model_engine_server/core/configs/config.yaml
                - name: CELERY_ELASTICACHE_ENABLED
                  value: "true"
                - name: LAUNCH_SERVICE_TEMPLATE_FOLDER
                  value: /workspace/model-engine/model_engine_server/infra/gateways/resources/templates
                - name: CIRCLECI
                  value: "true"
                - name: DD_VERSION
                  value: ${GIT_TAG}
                - name: GIT_TAG
                  value: ${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command:
                - dumb-init
                - --
              args:
                - python
                - -m
                - model_engine_server.entrypoints.start_batch_job_orchestration
                - --job-id
                - ${JOB_ID}
                - --owner
                - ${OWNER}
                - --input-path
                - ${INPUT_LOCATION}
                - --serialization-format
                - ${SERIALIZATION_FORMAT}
                - --timeout-seconds
                - "${BATCH_JOB_TIMEOUT}"
              resources:
                # If job pods get evicted, then we can make "Guaranteed QoS" by setting requests = limits.
                requests:
                  cpu: 1
                  memory: 8Gi
                  ephemeral-storage: 10Gi
                limits:
                  cpu: 4
                  memory: 32Gi
                  ephemeral-storage: 30Gi
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
  docker-image-batch-job-cpu.yaml: |-
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: ${RESOURCE_NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        launch_job_id: ${JOB_ID}
        tags.datadoghq.com/request_id: ${REQUEST_ID}
        tags.datadoghq.com/service: ${JOB_ID}
        tags.datadoghq.com/user_id: ${OWNER}
        tags.datadoghq.com/team: ${TEAM}
    spec:
      backoffLimit: 0
      activeDeadlineSeconds: ${BATCH_JOB_MAX_RUNTIME}
      ttlSecondsAfterFinished: ${BATCH_JOB_TTL_SECONDS_AFTER_FINISHED}
      completions: ${BATCH_JOB_NUM_WORKERS}
      parallelism: ${BATCH_JOB_NUM_WORKERS}
      completionMode: "Indexed"
      template:
        metadata:
          labels:
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            launch_job_id: ${JOB_ID}
            tags.datadoghq.com/request_id: ${REQUEST_ID}
            tags.datadoghq.com/service: ${JOB_ID}
            tags.datadoghq.com/user_id: ${OWNER}
            tags.datadoghq.com/team: ${TEAM}
            sidecar.istio.io/inject: "false"
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"source": "python", "service": "${RESOURCE_NAME}", "tags": ["env:circleci", "launch_job_id:${JOB_ID}"]}]'
            cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        spec:
          restartPolicy: Never
          serviceAccountName: default
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: workdir
              emptyDir: {}
            - name: dshm
              emptyDir:
                medium: Memory
          containers:
            - name: main
              image: ${IMAGE}
              env:
                - name: DD_SERVICE
                  value: ${RESOURCE_NAME}
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
                - name: DD_TRACE_ENABLED
                  value: "true"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_ENV
                  value: circleci
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: SERVICE_IDENTIFIER
                - name: GATEWAY_URL
                  value: http://model-engine.default:80
                - name: AWS_PROFILE
                  value: default
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: ECR_READ_AWS_PROFILE
                  value: default
                - name: DB_SECRET_AWS_PROFILE
                  value: default
                - name: S3_WRITE_AWS_PROFILE
                  value: default
                - name: ML_INFRA_DATABASE_URL
                  valueFrom:
                    secretKeyRef:
                      key: database_url
                      name: model-engine-postgres-credentials
                - name: DEPLOY_SERVICE_CONFIG_PATH
                  value: /workspace/model-engine/service_configs/service_config.yaml
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: /workspace/model-engine/model_engine_server/core/configs/config.yaml
                - name: CELERY_ELASTICACHE_ENABLED
                  value: "true"
                - name: LAUNCH_SERVICE_TEMPLATE_FOLDER
                  value: /workspace/model-engine/model_engine_server/infra/gateways/resources/templates
                - name: CIRCLECI
                  value: "true"
                - name: DD_VERSION
                  value: ${GIT_TAG}
                - name: GIT_TAG
                  value: ${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              resources:
                # If job pods get evicted, then we can make "Guaranteed QoS" by setting requests = limits.
                requests:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: workdir
                  mountPath: ${MOUNT_PATH}
                - mountPath: /dev/shm
                  name: dshm
          initContainers:
            - name: input-downloader
              image: model-engine:${GIT_TAG}
              env:
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
              command:
                - python
                - -m
                - model_engine_server.entrypoints.start_docker_image_batch_job_init_container
                - ${INPUT_LOCATION}
                - --remote-file
                - ${S3_FILE}
                - --local-file
                - ${LOCAL_FILE_NAME}
                - --file-contents-b64encoded
                - ${FILE_CONTENTS_B64ENCODED}
              resources:
                requests:
                  cpu: 1
                  memory: 1Gi
                limits:
                  cpu: 1
                  memory: 1Gi
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: workdir
                  mountPath: ${MOUNT_PATH}
  docker-image-batch-job-gpu.yaml: |-
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: ${RESOURCE_NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        env: circleci
        managed-by: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/env: circleci
        tags.datadoghq.com/version: ${GIT_TAG}
        launch_job_id: ${JOB_ID}
        tags.datadoghq.com/request_id: ${REQUEST_ID}
        tags.datadoghq.com/service: ${JOB_ID}
        tags.datadoghq.com/user_id: ${OWNER}
        tags.datadoghq.com/team: ${TEAM}
    spec:
      backoffLimit: 0
      activeDeadlineSeconds: ${BATCH_JOB_MAX_RUNTIME}
      ttlSecondsAfterFinished: ${BATCH_JOB_TTL_SECONDS_AFTER_FINISHED}
      completions: ${BATCH_JOB_NUM_WORKERS}
      parallelism: ${BATCH_JOB_NUM_WORKERS}
      completionMode: "Indexed"
      template:
        metadata:
          labels:
            user_id: ${OWNER}
            team: ${TEAM}
            product: ${PRODUCT}
            created_by: ${CREATED_BY}
            owner: ${OWNER}
            env: circleci
            managed-by: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/env: circleci
            tags.datadoghq.com/version: ${GIT_TAG}
            launch_job_id: ${JOB_ID}
            tags.datadoghq.com/request_id: ${REQUEST_ID}
            tags.datadoghq.com/service: ${JOB_ID}
            tags.datadoghq.com/user_id: ${OWNER}
            tags.datadoghq.com/team: ${TEAM}
            sidecar.istio.io/inject: "false"
            version: v1
          annotations:
            ad.datadoghq.com/main.logs: '[{"source": "python", "service": "${RESOURCE_NAME}", "tags": ["env:circleci", "launch_job_id:${JOB_ID}"]}]'
            cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        spec:
          restartPolicy: Never
          nodeSelector:
            k8s.amazonaws.com/accelerator: ${GPU_TYPE}
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          serviceAccountName: default
          volumes:
            - name: config-volume
              configMap:
                name: default-config
            - name: workdir
              emptyDir: {}
            - name: dshm
              emptyDir:
                medium: Memory
          containers:
            - name: main
              image: ${IMAGE}
              env:
                - name: DD_SERVICE
                  value: ${RESOURCE_NAME}
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
                - name: DD_TRACE_ENABLED
                  value: "true"
                - name: DD_REMOTE_CONFIGURATION_ENABLED
                  value: "false"
                - name: DD_ENV
                  value: circleci
                - name: DD_AGENT_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                - name: SERVICE_IDENTIFIER
                - name: GATEWAY_URL
                  value: http://model-engine.default:80
                - name: AWS_PROFILE
                  value: default
                - name: AWS_CONFIG_FILE
                  value: /opt/.aws/config
                - name: ECR_READ_AWS_PROFILE
                  value: default
                - name: DB_SECRET_AWS_PROFILE
                  value: default
                - name: S3_WRITE_AWS_PROFILE
                  value: default
                - name: ML_INFRA_DATABASE_URL
                  valueFrom:
                    secretKeyRef:
                      key: database_url
                      name: model-engine-postgres-credentials
                - name: DEPLOY_SERVICE_CONFIG_PATH
                  value: /workspace/model-engine/service_configs/service_config.yaml
                - name: ML_INFRA_SERVICES_CONFIG_PATH
                  value: /workspace/model-engine/model_engine_server/core/configs/config.yaml
                - name: CELERY_ELASTICACHE_ENABLED
                  value: "true"
                - name: LAUNCH_SERVICE_TEMPLATE_FOLDER
                  value: /workspace/model-engine/model_engine_server/infra/gateways/resources/templates
                - name: CIRCLECI
                  value: "true"
                - name: DD_VERSION
                  value: ${GIT_TAG}
                - name: GIT_TAG
                  value: ${GIT_TAG}
              imagePullPolicy: IfNotPresent
              command: ${COMMAND}
              resources:
                # If job pods get evicted, then we can make "Guaranteed QoS" by setting requests = limits.
                requests:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
                limits:
                  nvidia.com/gpu: ${GPUS}
                  cpu: ${CPUS}
                  memory: ${MEMORY}
                  ${STORAGE_DICT}
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: workdir
                  mountPath: ${MOUNT_PATH}
                - mountPath: /dev/shm
                  name: dshm
          initContainers:
            - name: input-downloader
              image: model-engine:${GIT_TAG}
              env:
                - name: AWS_CONFIG_FILE
                  value: "/opt/.aws/config"
              command:
                - python
                - -m
                - model_engine_server.entrypoints.start_docker_image_batch_job_init_container
                - ${INPUT_LOCATION}
                - --remote-file
                - ${S3_FILE}
                - --local-file
                - ${LOCAL_FILE_NAME}
                - --file-contents-b64encoded
                - ${FILE_CONTENTS_B64ENCODED}
              resources:
                requests:
                  cpu: 1
                  memory: 1Gi
                limits:
                  cpu: 1
                  memory: 1Gi
              volumeMounts:
                - name: config-volume
                  mountPath: /opt/.aws/config
                  subPath: config
                - name: workdir
                  mountPath: ${MOUNT_PATH}
  image-cache-cpu.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            cpu-only: "true"
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  image-cache-a10.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            k8s.amazonaws.com/accelerator: nvidia-ampere-a10
          tolerations:
            - effect: NoSchedule
              key: nvidia.com/gpu
              operator: Exists
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  image-cache-a100.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            k8s.amazonaws.com/accelerator: nvidia-ampere-a100
          tolerations:
            - effect: NoSchedule
              key: nvidia.com/gpu
              operator: Exists
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  image-cache-t4.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            k8s.amazonaws.com/accelerator: nvidia-tesla-t4
          tolerations:
            - effect: NoSchedule
              key: nvidia.com/gpu
              operator: Exists
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  image-cache-h100.yaml: |-
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: ${RESOURCE_NAME}
      namespace: ${NAMESPACE}
      labels:
        team: infra
        product: model-engine
        use_scale_launch_endpoint_network_policy: "true"
        tags.datadoghq.com/service: ${RESOURCE_NAME}
    spec:
      selector:
        matchLabels:
          app: ${RESOURCE_NAME}
          version: v1
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: ${RESOURCE_NAME}
            team: infra
            product: model-engine
            use_scale_launch_endpoint_network_policy: "true"
            tags.datadoghq.com/service: ${RESOURCE_NAME}
            version: v1
            sidecar.istio.io/inject: "false"
        spec:
          nodeSelector:
            k8s.amazonaws.com/accelerator: nvidia-hopper-h100
          tolerations:
            - effect: NoSchedule
              key: nvidia.com/gpu
              operator: Exists
          containers:
            - image: public.ecr.aws/docker/library/busybox:latest
              imagePullPolicy: IfNotPresent
              name: busybox
              command: ["/bin/sh", "-ec", "while : ; do sleep 30 ; done"]
          terminationGracePeriodSeconds: 0
  cron-trigger.yaml: |-
    apiVersion: batch/v1
    kind: CronJob
    metadata:
      name: ${NAME}
      labels:
        user_id: ${OWNER}
        team: ${TEAM}
        product: ${PRODUCT}
        created_by: ${CREATED_BY}
        owner: ${OWNER}
        launch_trigger_id: ${TRIGGER_ID}
        tags.datadoghq.com/service: ${TRIGGER_ID}
    spec:
      schedule: "${CRON_SCHEDULE}"
      successfulJobsHistoryLimit: 0
      failedJobsHistoryLimit: 0
      jobTemplate:
        spec:
          backoffLimit: 0
          activeDeadlineSeconds: ${BATCH_CURL_JOB_ACTIVE_DEADLINE_SECONDS}
          template:
            metadata:
              labels:
                user_id: ${OWNER}
                team: ${TEAM}
                product: ${PRODUCT}
                created_by: ${CREATED_BY}
                owner: ${OWNER}
                launch_trigger_id: ${TRIGGER_ID}
                tags.datadoghq.com/service: ${TRIGGER_ID}
            spec:
              containers:
              - name: ${NAME}
                image: curlimages/curl:7.72.0
                imagePullPolicy: IfNotPresent
                command:
                - curl
                - -X
                - 'POST'
                - '${HOST}/v1/docker-image-batch-jobs'
                - -H
                - 'accept: application/json'
                - -H
                - 'Content-Type: application/json'
                - -d
                - '{ "docker_image_batch_job_bundle_id": "${DOCKER_IMAGE_BATCH_JOB_BUNDLE_ID}", "job_config": ${JOB_CONFIG}, "labels": ${JOB_METADATA}  }'
                - -u
                - '${OWNER}:'
              restartPolicy: Never
