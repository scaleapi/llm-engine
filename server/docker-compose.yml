version: "3.8"

services:
  llm-engine:
    build:
      context: ..
      dockerfile: llm_engine/Dockerfile
      secrets:
        - codeartifact-pip-conf
      target: llm-engine
    image: "${ECR_HOST:-local}/llm-engine:${GIT_SHA:-latest}"
  llm-engine-gateway-dev:
    build:
      context: ..
      dockerfile: llm_engine/Dockerfile
      secrets:
        - codeartifact-pip-conf
      target: llm-engine
    command:
      - python
      - -m
      - hosted_model_inference.entrypoints.start_fastapi_server
      - --port=5001
      - --debug
      - --num-workers=1
    environment:
      - AWS_PROFILE
      - SQS_PROFILE
      - KUBECONFIG=/workspace/.kube/kubeconfig:/workspace/.kube/config
      - SERVICE_IDENTIFIER
      - AWS_CONFIG_FILE=/creds/.aws/config
      - AWS_SHARED_CREDENTIALS_FILE=/creds/.aws/credentials
      - CELERY_ELASTICACHE_ENABLED=true
      - "GIT_TAG=${GIT_SHA}"
      - DD_ENV=training
      - "DEPLOY_SERVICE_CONFIG_PATH=/workspace/hosted_model_inference/service_configs/service_config_${ENV}.yaml"
      - "LLM_ENGINE_SERVICE_TEMPLATE_CONFIG_MAP_PATH=/workspace/hosted_model_inference/hosted_model_inference/infra/gateways/resources/templates/service_template_config_map_${ENV}.yaml"
      - "ML_INFRA_SERVICES_CONFIG_PATH=/workspace/ml_infra_core/ml_infra_services/ml_infra_services/configs/${ENV}.yaml"
      - "DB_SECRET_NAME=${DB_SECRET_NAME:-}"
      - "ML_INFRA_DATABASE_URL=${ML_INFRA_DATABASE_URL:-}"
      - "USE_REDIS_LOCALHOST=${USE_REDIS_LOCALHOST:-}"
      - "SKIP_AUTH=${SKIP_AUTH:-}"
      - "CIRCLECI=${CIRCLECI:-}"
      - "LOCAL=${LOCAL:-false}"
    network_mode: host
    ports:
      - 5001:5001
    stdin_open: true
    tty: true
    volumes:
      - "${HOME}/.kube:/workspace/.kube"
      - "${HOME}/.minikube:/workspace/.minikube"
      - "${HOME}/.minikube:/home/circleci/.minikube"
      - "${HOME}/.aws-mountable:/creds/.aws"
      - "../llm_engine:/workspace/llm_engine"
  llm-engine-service-builder-dev:
    build:
      context: ..
      dockerfile: llm_engine/Dockerfile
      secrets:
        - codeartifact-pip-conf
      target: llm-engine
    command:
      - celery
      - --app=hosted_model_inference.service_builder
      - worker
      - --loglevel=INFO
      - --concurrency=4
      - "--queues=${QUEUE}"
    environment:
      - AWS_PROFILE
      - SQS_PROFILE
      - ECR_READ_AWS_PROFILE
      - DB_SECRET_AWS_PROFILE
      - "S3_BUCKET=${S3_BUCKET:-scale-ml}"
      - "DEPLOY_SERVICE_CONFIG_PATH=/workspace/hosted_model_inference/service_configs/service_config_${ENV}.yaml"
      - "LLM_ENGINE_SERVICE_TEMPLATE_CONFIG_MAP_PATH=/workspace/hosted_model_inference/hosted_model_inference/infra/gateways/resources/templates/service_template_config_map_${ENV}.yaml"
      - "ML_INFRA_SERVICES_CONFIG_PATH=/workspace/ml_infra_core/ml_infra_services/ml_infra_services/configs/${ENV}.yaml"
      - "GIT_TAG=${GIT_SHA}"
      - DD_ENV=training
      - SERVICE_IDENTIFIER
      - KUBECONFIG=/workspace/.kube/kubeconfig:/workspace/.kube/config
      - AWS_CONFIG_FILE=/creds/.aws/config
      - AWS_SHARED_CREDENTIALS_FILE=/creds/.aws/credentials
      - CELERY_ELASTICACHE_ENABLED=true
      - "KANIKO_TEMPLATE=${KANIKO_TEMPLATE:-kaniko_template.yaml}"
      - "DB_SECRET_NAME=${DB_SECRET_NAME:-}"
      - "ML_INFRA_DATABASE_URL=${ML_INFRA_DATABASE_URL:-}"
      - "USE_REDIS_LOCALHOST=${USE_REDIS_LOCALHOST:-}"
      - "SKIP_AUTH=${SKIP_AUTH:-}"
      - "CIRCLECI=${CIRCLECI:-}"
      - "LOCAL=${LOCAL:-false}"
    network_mode: host
    stdin_open: true
    tty: true
    volumes:
      - "${HOME}/.kube:/workspace/.kube"
      - "${HOME}/.minikube:/workspace/.minikube"
      - "${HOME}/.minikube:/home/circleci/.minikube"
      - "${HOME}/.aws-mountable:/creds/.aws"
      - "../llm_engine:/workspace/llm_engine"
  llm-engine-bash:
    build:
      context: ..
      dockerfile: llm_engine/Dockerfile
      secrets:
        - codeartifact-pip-conf
      target: llm-engine
    command:
      - /bin/bash
      - -c
      - "'${BASH_COMMAND:-/bin/bash}'"
    environment:
      - AWS_PROFILE
      - SQS_PROFILE
      - ECR_READ_AWS_PROFILE
      - DB_SECRET_AWS_PROFILE
      - "DEPLOY_SERVICE_CONFIG_PATH=/workspace/hosted_model_inference/service_configs/service_config_${ENV}.yaml"
      - "LLM_ENGINE_SERVICE_TEMPLATE_CONFIG_MAP_PATH=/workspace/hosted_model_inference/hosted_model_inference/infra/gateways/resources/templates/service_template_config_map_${ENV}.yaml"
      - "ML_INFRA_SERVICES_CONFIG_PATH=/workspace/ml_infra_core/ml_infra_services/ml_infra_services/configs/${ENV}.yaml"
      - "GIT_TAG=${GIT_SHA}"
      - DD_ENV=training
      - SERVICE_IDENTIFIER
      - KUBECONFIG=/workspace/.kube/kubeconfig:/workspace/.kube/config
      - AWS_CONFIG_FILE=/creds/.aws/config
      - AWS_SHARED_CREDENTIALS_FILE=/creds/.aws/credentials
      - CELERY_ELASTICACHE_ENABLED=true
      - "DB_SECRET_NAME=${DB_SECRET_NAME:-}"
      - "ML_INFRA_DATABASE_URL=${ML_INFRA_DATABASE_URL:-}"
      - "USE_REDIS_LOCALHOST=${USE_REDIS_LOCALHOST:-}"
      - "CIRCLECI=${CIRCLECI:-}"
      - "LOCAL=${LOCAL:-false}"
    network_mode: host
    ports:
      - 5002:5000
    volumes:
      - "${HOME}/.kube:/workspace/.kube"
      - "${HOME}/.minikube:/workspace/.minikube"
      - "${HOME}/.minikube:/home/circleci/.minikube"
      - "${HOME}/.aws-mountable:/creds/.aws"
      - "../llm_engine:/workspace/llm_engine"
  db:
    image: "cimg/postgres:12.8-postgis"
    ports:
      - 5432:5432
    environment:
      - POSTGRES_USER=ml_infra_test
      - POSTGRES_DB=ml_infra_test
      - POSTGRES_PASSWORD=ml_infra_test
  redis:
    image: redis
    ports:
      - 6379:6379
  openapi-generator-cli:
    image: "${ECR_HOST:-local}/ml_infra_core/openapi:${GIT_SHA:-latest}"
    build:
      context: ..
      dockerfile: ml_infra_core/Dockerfile.openapi
      target: base
    volumes:
      - "../llm_engine/clients:/local"
    command:
      - generate

secrets:
  codeartifact-pip-conf:
    file: ../.codeartifact-pip-conf
