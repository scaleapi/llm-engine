
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="The open source engine for fine-tuning large language models.">
      
      
      
      
        <link rel="prev" href="../../model_zoo/">
      
      
        <link rel="next" href="../fine_tuning/">
      
      
      <link rel="icon" href="https://raw.githubusercontent.com/scaleapi/llm-engine/main/docs/_static/favicon-32x32.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.7">
    
    
      
        <title>Completions - LLM Engine</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CIBM+Plex+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"IBM Plex Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/index.css">
    
      <link rel="stylesheet" href="../../assets/css/extra.css">
    
      <link rel="stylesheet" href="../../assets/css/neoteroi.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-N54ZLW5PGC"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-N54ZLW5PGC",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-N54ZLW5PGC",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#completion-api-call" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="LLM Engine" class="md-header__button md-logo" aria-label="LLM Engine" data-md-component="logo">
      
  <img src="https://raw.githubusercontent.com/scaleapi/llm-engine/main/docs/_static/favicon-32x32.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLM Engine
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Completions
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="deep-purple"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/scaleapi/llm-engine" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    llm-engine
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="LLM Engine" class="md-nav__button md-logo" aria-label="LLM Engine" data-md-component="logo">
      
  <img src="https://raw.githubusercontent.com/scaleapi/llm-engine/main/docs/_static/favicon-32x32.png" alt="logo">

    </a>
    LLM Engine
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/scaleapi/llm-engine" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    llm-engine
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_zoo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Zoo
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Completions
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Completions
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#completion-api-call" class="md-nav__link">
    <span class="md-ellipsis">
      Completion API call
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#completion-api-response" class="md-nav__link">
    <span class="md-ellipsis">
      Completion API response
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#token-streaming" class="md-nav__link">
    <span class="md-ellipsis">
      Token streaming
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Token streaming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#streaming-error-handling" class="md-nav__link">
    <span class="md-ellipsis">
      Streaming Error Handling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#async-requests" class="md-nav__link">
    <span class="md-ellipsis">
      Async requests
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-completions" class="md-nav__link">
    <span class="md-ellipsis">
      Batch completions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#guided-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      Guided decoding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#which-model-should-i-use" class="md-nav__link">
    <span class="md-ellipsis">
      Which model should I use?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine_tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rate_limits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Rate limits
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../self_hosting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Self Hosting
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/python_client/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/data_types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Type Reference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/error_handling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Error handling
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../integrations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Integrations
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pricing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pricing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contributing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#completion-api-call" class="md-nav__link">
    <span class="md-ellipsis">
      Completion API call
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#completion-api-response" class="md-nav__link">
    <span class="md-ellipsis">
      Completion API response
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#token-streaming" class="md-nav__link">
    <span class="md-ellipsis">
      Token streaming
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Token streaming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#streaming-error-handling" class="md-nav__link">
    <span class="md-ellipsis">
      Streaming Error Handling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#async-requests" class="md-nav__link">
    <span class="md-ellipsis">
      Async requests
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-completions" class="md-nav__link">
    <span class="md-ellipsis">
      Batch completions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#guided-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      Guided decoding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#which-model-should-i-use" class="md-nav__link">
    <span class="md-ellipsis">
      Which model should I use?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>Completions</h1>

<p>Language Models are trained to predict natural language and provide text outputs as a response
to their inputs. The inputs are called <em>prompts</em> and outputs are referred to as <em>completions</em>.
LLMs take the input <em>prompts</em> and chunk them into smaller units called <em>tokens</em> to process and
generate language. Tokens may include trailing spaces and even sub-words. This process is
language dependent.</p>
<p>Scale's LLM Engine provides access to open source language models (see <a href="../../model_zoo">Model Zoo</a>)
that can be used for producing completions to prompts.</p>
<h2 id="completion-api-call">Completion API call<a class="headerlink" href="#completion-api-call" title="Permanent link">&para;</a></h2>
<p>An example API call looks as follows:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:1"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">Completion call in Python</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>response <span style="color: #666">=</span> Completion<span style="color: #666">.</span>create(
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    prompt<span style="color: #666">=</span><span style="color: #BA2121">&quot;Hello, my name is&quot;</span>,
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    max_new_tokens<span style="color: #666">=10</span>,
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    temperature<span style="color: #666">=0.2</span>,
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>)
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>json())
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span style="color: #3D7B7B; font-style: italic"># &#39;{&quot;request_id&quot;: &quot;c4bf0732-08e0-48a8-8b44-dfe8d4702fb0&quot;, &quot;output&quot;: {&quot;text&quot;: &quot;________ and I am a ________&quot;, &quot;num_completion_tokens&quot;: 10}}&#39;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>output<span style="color: #666">.</span>text)
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span style="color: #3D7B7B; font-style: italic"># ________ and I am a ________</span>
</code></pre></div>
<ul>
<li><strong>model:</strong> The LLM you want to use (see <a href="../../model_zoo">Model Zoo</a>).</li>
<li><strong>prompt:</strong> The main input for the LLM to respond to.</li>
<li><strong>max_new_tokens:</strong> The maximum number of tokens to generate in the chat completion.</li>
<li><strong>temperature:</strong> The sampling temperature to use. Higher values make the output more random,
  while lower values will make it more focused and deterministic.
  When temperature is 0 <a href="https://huggingface.co/docs/transformers/generation_strategies#greedy-search">greedy search</a> is used.</li>
</ul>
<p>See the full <a href="../../api/python_client/#llmengine.Completion">Completion API reference documentation</a> to learn more.</p>
<h2 id="completion-api-response">Completion API response<a class="headerlink" href="#completion-api-response" title="Permanent link">&para;</a></h2>
<p>An example Completion API response looks as follows:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Response in JSON</label><label for="__tabbed_2_2">Response in Python</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>    <span style="color: #666">&gt;&gt;&gt;</span> <span style="color: #008000">print</span>(response<span style="color: #666">.</span>json())
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    {
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>      <span style="color: #BA2121">&quot;request_id&quot;</span>: <span style="color: #BA2121">&quot;c4bf0732-08e0-48a8-8b44-dfe8d4702fb0&quot;</span>,
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>      <span style="color: #BA2121">&quot;output&quot;</span>: {
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>        <span style="color: #BA2121">&quot;text&quot;</span>: <span style="color: #BA2121">&quot;_______ and I am a _______&quot;</span>,
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>        <span style="color: #BA2121">&quot;num_completion_tokens&quot;</span>: <span style="color: #666">10</span>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>      }
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    }
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>    <span style="color: #666">&gt;&gt;&gt;</span> <span style="color: #008000">print</span>(response<span style="color: #666">.</span>output<span style="color: #666">.</span>text)
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>    _______ <span style="color: #A2F; font-weight: bold">and</span> I am a _______
</code></pre></div>
</div>
</div>
</div>
<h2 id="token-streaming">Token streaming<a class="headerlink" href="#token-streaming" title="Permanent link">&para;</a></h2>
<p>The Completions API supports token streaming to reduce <em>perceived</em> latency for certain
applications. When streaming, tokens will be sent as data-only
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#event_stream_format">server-side events</a>.</p>
<p>To enable token streaming, pass <code>stream=True</code> to either <a href="../../api/python_client/#llmengine.completion.Completion.create">Completion.create</a> or <a href="../../api/python_client/#llmengine.completion.Completion.acreate">Completion.acreate</a>.</p>
<h3 id="streaming-error-handling">Streaming Error Handling<a class="headerlink" href="#streaming-error-handling" title="Permanent link">&para;</a></h3>
<p>Note: Error handling semantics are mixed for streaming calls:
- Errors that arise <em>before</em> streaming begins are returned back to the user as <code>HTTP</code> errors with the appropriate status code.
- Errors that arise <em>after</em> streaming begins within a <code>HTTP 200</code> response are returned back to the user as plain-text messages and currently need to be handled by the client. </p>
<p>An example of token streaming using the synchronous Completions API looks as follows:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:1"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">Token streaming with synchronous API in python</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span style="color: #008000; font-weight: bold">import</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">sys</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span style="color: #3D7B7B; font-style: italic"># errors occurring before streaming begins will be thrown here</span>
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>stream <span style="color: #666">=</span> Completion<span style="color: #666">.</span>create(
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>    prompt<span style="color: #666">=</span><span style="color: #BA2121">&quot;Give me a 200 word summary on the current economic events in the US.&quot;</span>,
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>    max_new_tokens<span style="color: #666">=1000</span>,
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    temperature<span style="color: #666">=0.2</span>,
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>    stream<span style="color: #666">=</span><span style="color: #008000; font-weight: bold">True</span>,
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>)
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a><span style="color: #008000; font-weight: bold">for</span> response <span style="color: #A2F; font-weight: bold">in</span> stream:
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>    <span style="color: #008000; font-weight: bold">if</span> response<span style="color: #666">.</span>output:
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>        <span style="color: #008000">print</span>(response<span style="color: #666">.</span>output<span style="color: #666">.</span>text, end<span style="color: #666">=</span><span style="color: #BA2121">&quot;&quot;</span>)
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>        sys<span style="color: #666">.</span>stdout<span style="color: #666">.</span>flush()
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>    <span style="color: #008000; font-weight: bold">else</span>: <span style="color: #3D7B7B; font-style: italic"># an error occurred after streaming began</span>
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>        <span style="color: #008000">print</span>(response<span style="color: #666">.</span>error) <span style="color: #3D7B7B; font-style: italic"># print the error message out </span>
<a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>        <span style="color: #008000; font-weight: bold">break</span>
</code></pre></div>
<h2 id="async-requests">Async requests<a class="headerlink" href="#async-requests" title="Permanent link">&para;</a></h2>
<p>The Python client supports <code>asyncio</code> for creating Completions. Use <a href="../../api/python_client/#llmengine.completion.Completion.acreate">Completion.acreate</a> instead of <a href="../../api/python_client/#llmengine.completion.Completion.create">Completion.create</a>
to utilize async processing. The function signatures are otherwise identical.</p>
<p>An example of async Completions looks as follows:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:1"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">Completions with asynchronous API in python</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span style="color: #008000; font-weight: bold">import</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">asyncio</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span style="color: #008000; font-weight: bold">async</span> <span style="color: #008000; font-weight: bold">def</span><span style="color: #BBB"> </span><span style="color: #00F">main</span>():
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>    response <span style="color: #666">=</span> <span style="color: #008000; font-weight: bold">await</span> Completion<span style="color: #666">.</span>acreate(
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>        model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>        prompt<span style="color: #666">=</span><span style="color: #BA2121">&quot;Hello, my name is&quot;</span>,
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>        max_new_tokens<span style="color: #666">=10</span>,
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>        temperature<span style="color: #666">=0.2</span>,
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>    )
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>    <span style="color: #008000">print</span>(response<span style="color: #666">.</span>json())
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>asyncio<span style="color: #666">.</span>run(main())
</code></pre></div>
<h2 id="batch-completions">Batch completions<a class="headerlink" href="#batch-completions" title="Permanent link">&para;</a></h2>
<p>The Python client also supports batch completions. Batch completions supports distributing data to multiple workers to accelerate inference. It also tries to maximize throughput so the completions should finish quite a bit faster than hitting models through HTTP. Use <a href="../../api/python_client/#llmengine.Completion.batch_create">Completion.batch_create</a> to utilize batch completions.</p>
<p>Some examples of batch completions:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:1"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">Batch completions with prompts in the request</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine.data_types</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> CreateBatchCompletionsModelConfig, CreateBatchCompletionsRequestContent
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>content <span style="color: #666">=</span> CreateBatchCompletionsRequestContent(
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>    prompts<span style="color: #666">=</span>[<span style="color: #BA2121">&quot;What is deep learning&quot;</span>, <span style="color: #BA2121">&quot;What is a neural network&quot;</span>],
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>    max_new_tokens<span style="color: #666">=10</span>,
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>    temperature<span style="color: #666">=0.0</span>
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>)
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>response <span style="color: #666">=</span> Completion<span style="color: #666">.</span>batch_create(
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>    output_data_path<span style="color: #666">=</span><span style="color: #BA2121">&quot;s3://my-path&quot;</span>,
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>    model_config<span style="color: #666">=</span>CreateBatchCompletionsModelConfig(
<a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>        model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>        checkpoint_path<span style="color: #666">=</span><span style="color: #BA2121">&quot;s3://checkpoint-path&quot;</span>,
<a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>        labels<span style="color: #666">=</span>{<span style="color: #BA2121">&quot;team&quot;</span>:<span style="color: #BA2121">&quot;my-team&quot;</span>, <span style="color: #BA2121">&quot;product&quot;</span>:<span style="color: #BA2121">&quot;my-product&quot;</span>}
<a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>    ),
<a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>    content<span style="color: #666">=</span>content
<a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>)
<a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>job_id)
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="6:1"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">Batch completions with prompts in a file and with 2 parallel jobs</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine.data_types</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> CreateBatchCompletionsModelConfig, CreateBatchCompletionsRequestContent
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span style="color: #3D7B7B; font-style: italic"># Store CreateBatchCompletionsRequestContent data into input file &quot;s3://my-input-path&quot;</span>
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>response <span style="color: #666">=</span> Completion<span style="color: #666">.</span>batch_create(
<a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>    input_data_path<span style="color: #666">=</span><span style="color: #BA2121">&quot;s3://my-input-path&quot;</span>,
<a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>    output_data_path<span style="color: #666">=</span><span style="color: #BA2121">&quot;s3://my-output-path&quot;</span>,
<a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>    model_config<span style="color: #666">=</span>CreateBatchCompletionsModelConfig(
<a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>        model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>        checkpoint_path<span style="color: #666">=</span><span style="color: #BA2121">&quot;s3://checkpoint-path&quot;</span>,
<a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>        labels<span style="color: #666">=</span>{<span style="color: #BA2121">&quot;team&quot;</span>:<span style="color: #BA2121">&quot;my-team&quot;</span>, <span style="color: #BA2121">&quot;product&quot;</span>:<span style="color: #BA2121">&quot;my-product&quot;</span>}
<a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>    ),
<a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>    data_parallelism<span style="color: #666">=2</span>
<a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>)
<a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>job_id)
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="7:1"><input checked="checked" id="__tabbed_7_1" name="__tabbed_7" type="radio" /><div class="tabbed-labels"><label for="__tabbed_7_1">Batch completions with prompts and use tool</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<p>For how to properly use the tool please see <a href="../../api/python_client/#llmengine.Completion.batch_create">Completion.batch_create</a> tool_config doc.
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine.data_types</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> CreateBatchCompletionsModelConfig, CreateBatchCompletionsRequestContent, ToolConfig
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span style="color: #3D7B7B; font-style: italic"># Store CreateBatchCompletionsRequestContent data into input file &quot;s3://my-input-path&quot;</span>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>response <span style="color: #666">=</span> Completion<span style="color: #666">.</span>batch_create(
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>    input_data_path<span style="color: #666">=</span><span style="color: #BA2121">&quot;s3://my-input-path&quot;</span>,
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>    output_data_path<span style="color: #666">=</span><span style="color: #BA2121">&quot;s3://my-output-path&quot;</span>,
<a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>    model_config<span style="color: #666">=</span>CreateBatchCompletionsModelConfig(
<a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>        model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a>        checkpoint_path<span style="color: #666">=</span><span style="color: #BA2121">&quot;s3://checkpoint-path&quot;</span>,
<a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>        labels<span style="color: #666">=</span>{<span style="color: #BA2121">&quot;team&quot;</span>:<span style="color: #BA2121">&quot;my-team&quot;</span>, <span style="color: #BA2121">&quot;product&quot;</span>:<span style="color: #BA2121">&quot;my-product&quot;</span>}
<a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a>    ),
<a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a>    data_parallelism<span style="color: #666">=2</span>,
<a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a>    tool_config<span style="color: #666">=</span>ToolConfig(
<a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>        name<span style="color: #666">=</span><span style="color: #BA2121">&quot;code_evaluator&quot;</span>,
<a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a>    )
<a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a>)
<a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>json())
</code></pre></div></p>
<h2 id="guided-decoding">Guided decoding<a class="headerlink" href="#guided-decoding" title="Permanent link">&para;</a></h2>
<p>Guided decoding is supported by vLLM and backed by <a href="https://github.com/outlines-dev/outlines">Outlines</a>.
It enforces certain token generation patterns by tinkering with the sampling logits.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="8:1"><input checked="checked" id="__tabbed_8_1" name="__tabbed_8" type="radio" /><div class="tabbed-labels"><label for="__tabbed_8_1">Guided decoding with regex</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>response <span style="color: #666">=</span> Completion<span style="color: #666">.</span>create(
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>    model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>    prompt<span style="color: #666">=</span><span style="color: #BA2121">&quot;Hello, my name is&quot;</span>,
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>    max_new_tokens<span style="color: #666">=10</span>,
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>    temperature<span style="color: #666">=0.2</span>,
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>    guided_regex<span style="color: #666">=</span><span style="color: #BA2121">&quot;Sean.*&quot;</span>,
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>)
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>json())
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a><span style="color: #3D7B7B; font-style: italic"># {&quot;request_id&quot;:&quot;c19f0fae-317e-4f69-8e06-c04189299b9c&quot;,&quot;output&quot;:{&quot;text&quot;:&quot;Sean. I&#39;m a 2&quot;,&quot;num_prompt_tokens&quot;:6,&quot;num_completion_tokens&quot;:10,&quot;tokens&quot;:null}}</span>
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="9:1"><input checked="checked" id="__tabbed_9_1" name="__tabbed_9" type="radio" /><div class="tabbed-labels"><label for="__tabbed_9_1">Guided decoding with choice</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>response <span style="color: #666">=</span> Completion<span style="color: #666">.</span>create(
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>    model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>    prompt<span style="color: #666">=</span><span style="color: #BA2121">&quot;Hello, my name is&quot;</span>,
<a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>    max_new_tokens<span style="color: #666">=10</span>,
<a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>    temperature<span style="color: #666">=0.2</span>,
<a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>    guided_choice<span style="color: #666">=</span>[<span style="color: #BA2121">&quot;Sean&quot;</span>, <span style="color: #BA2121">&quot;Brian&quot;</span>, <span style="color: #BA2121">&quot;Tim&quot;</span>],
<a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>)
<a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>
<a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>json())
<a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a><span style="color: #3D7B7B; font-style: italic"># {&quot;request_id&quot;:&quot;641e2af3-a3e3-4493-98b9-d38115ba0d22&quot;,&quot;output&quot;:{&quot;text&quot;:&quot;Sean&quot;,&quot;num_prompt_tokens&quot;:6,&quot;num_completion_tokens&quot;:4,&quot;tokens&quot;:null}}</span>
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="10:1"><input checked="checked" id="__tabbed_10_1" name="__tabbed_10" type="radio" /><div class="tabbed-labels"><label for="__tabbed_10_1">Guided decoding with JSON schema</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>response <span style="color: #666">=</span> Completion<span style="color: #666">.</span>create(
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>    model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>    prompt<span style="color: #666">=</span><span style="color: #BA2121">&quot;Hello, my name is&quot;</span>,
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>    max_new_tokens<span style="color: #666">=10</span>,
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>    temperature<span style="color: #666">=0.2</span>,
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>    guided_json<span style="color: #666">=</span>{<span style="color: #BA2121">&quot;properties&quot;</span>:{<span style="color: #BA2121">&quot;myString&quot;</span>:{<span style="color: #BA2121">&quot;type&quot;</span>:<span style="color: #BA2121">&quot;string&quot;</span>}},<span style="color: #BA2121">&quot;required&quot;</span>:[<span style="color: #BA2121">&quot;myString&quot;</span>]},
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>)
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>json())
<a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a><span style="color: #3D7B7B; font-style: italic"># {&quot;request_id&quot;:&quot;5b184654-96b6-4932-9eb6-382a51fdb3d5&quot;,&quot;output&quot;:{&quot;text&quot;:&quot;{\&quot;myString\&quot; : \&quot;John Doe&quot;,&quot;num_prompt_tokens&quot;:6,&quot;num_completion_tokens&quot;:10,&quot;tokens&quot;:null}}</span>
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="11:1"><input checked="checked" id="__tabbed_11_1" name="__tabbed_11" type="radio" /><div class="tabbed-labels"><label for="__tabbed_11_1">Guided decoding with Context-Free Grammar</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span style="color: #008000; font-weight: bold">from</span><span style="color: #BBB"> </span><span style="color: #00F; font-weight: bold">llmengine</span><span style="color: #BBB"> </span><span style="color: #008000; font-weight: bold">import</span> Completion
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>response <span style="color: #666">=</span> Completion<span style="color: #666">.</span>create(
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>    model<span style="color: #666">=</span><span style="color: #BA2121">&quot;llama-2-7b&quot;</span>,
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>    prompt<span style="color: #666">=</span><span style="color: #BA2121">&quot;Hello, my name is&quot;</span>,
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    max_new_tokens<span style="color: #666">=10</span>,
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>    temperature<span style="color: #666">=0.2</span>,
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>    guided_grammar<span style="color: #666">=</span><span style="color: #BA2121">&quot;start: </span><span style="color: #AA5D1F; font-weight: bold">\&quot;</span><span style="color: #BA2121">John</span><span style="color: #AA5D1F; font-weight: bold">\&quot;</span><span style="color: #BA2121">&quot;</span>
<a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>)
<a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>
<a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a><span style="color: #008000">print</span>(response<span style="color: #666">.</span>json())
<a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a><span style="color: #3D7B7B; font-style: italic"># {&quot;request_id&quot;: &quot;34621b44-c655-402c-a459-f108b3e49b12&quot;, &quot;output&quot;: {&quot;text&quot;: &quot;John&quot;, &quot;num_prompt_tokens&quot;: 6, &quot;num_completion_tokens&quot;: 4, &quot;tokens&quot;: None}}</span>
</code></pre></div>
<h2 id="which-model-should-i-use">Which model should I use?<a class="headerlink" href="#which-model-should-i-use" title="Permanent link">&para;</a></h2>
<p>See the <a href="../../model_zoo">Model Zoo</a> for more information on best practices for which model to use for Completions.</p>









  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              Thanks for your feedback! Help us improve this page by using our <a href="..." target="_blank" rel="noopener">feedback form</a>.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["search.suggest", "search.highlight", "content.tabs.link", "content.code.annotate", "navigation.expand", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>