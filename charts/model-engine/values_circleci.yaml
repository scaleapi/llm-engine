# This is a YAML-formatted file.

replicaCount:
  gateway: 1
  cacher: 1
  builder: 1
  balloonA10: 0
  balloonA100: 0
  balloonCpu: 0
  balloonT4: 0

# tag needs to be set dynamically every time. Usually it is set to the SHA1 hash of the git
# commit from which the image was built.
# tag:
context: circleci
image:
  gatewayRepository: model-engine
  builderRepository: model-engine
  cacherRepository: model-engine
  forwarderRepository: model-engine
  pullPolicy: IfNotPresent

# serviceIdentifier:

secrets:
  kubernetesDatabaseSecretName: model-engine-postgres-credentials


service:
  type: ClusterIP
  port: 80

virtualservice:
  enabled: true
  annotations: { }
  hostDomains:
    - example.com
  gateways:
    - default/internal-gateway

hostDomain:
  prefix: http://

destinationrule:
  enabled: true
  annotations: { }

autoscaling:
  horizontal:
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    targetConcurrency: 30
  vertical:
    enabled: false
    minAllowed:
      cpu: 100m
      memory: 128Mi
    maxAllowed:
      cpu: 10
      memory: 8Gi
    updateMode: Auto
  prewarming:
    enabled: false

celery_autoscaler:
  enabled: false

podDisruptionBudget:
  enabled: true
  minAvailable: 1

resources:
  requests:
    cpu: 2

nodeSelector: null

balloonNodeSelector: null

tolerations: [ ]

affinity: { }

config:
  values:
    infra:
      k8s_cluster_name: minikube
      dns_host_domain: localhost
      default_region: us-west-2
      ml_account_id: "$CIRCLECI_AWS_ACCOUNT_ID"
      docker_repo_prefix: "$CIRCLECI_AWS_ACCOUNT_ID.dkr.ecr.us-west-2.amazonaws.com"
      redis_host: redis-message-broker-master.default
      s3_bucket: "$CIRCLECI_AWS_S3_BUCKET"
      profile_ml_worker: "default"
      profile_ml_inference_worker: "default"
    launch:
      # Endpoint config
      # K8s namespace the endpoints will be created in
      endpoint_namespace: model-engine
      model_primitive_host: none

      # Asynchronous endpoints
      sqs_profile: default
      sqs_queue_policy_template: >
        {
            "Version": "2012-10-17",
            "Id": "__default_policy_ID",
            "Statement": [
              {
                "Sid": "__owner_statement",
                "Effect": "Allow",
                "Principal": {
                  "AWS": "arn:aws:iam::$CIRCLECI_AWS_ACCOUNT_ID:root"
                },
                "Action": "sqs:*",
                "Resource": "arn:aws:sqs:us-west-2:$CIRCLECI_AWS_ACCOUNT_ID:${queue_name}"
              },
              {
                "Effect": "Allow",
                "Principal": {
                  "AWS": "arn:aws:iam::$CIRCLECI_AWS_ACCOUNT_ID:role/default"
                },
                "Action": "sqs:*",
                "Resource": "arn:aws:sqs:us-west-2:$CIRCLECI_AWS_ACCOUNT_ID:${queue_name}"
              },
              {
                "Effect": "Allow",
                "Principal": {
                  "AWS": "arn:aws:iam::$CIRCLECI_AWS_ACCOUNT_ID:role/ml_llm_engine"
                },
                "Action": "sqs:*",
                "Resource": "arn:aws:sqs:us-west-2:$CIRCLECI_AWS_ACCOUNT_ID:${queue_name}"
              }
            ]
          }
      sqs_queue_tag_template: >
        {
          "Spellbook-Serve-Endpoint-Id": "${endpoint_id}",
          "Spellbook-Serve-Endpoint-Name": "${endpoint_name}",
          "Spellbook-Serve-Endpoint-Created-By": "${endpoint_created_by}"
        }

      billing_queue_arn: none
      cache_redis_url: redis://redis-message-broker-master.default/15
      s3_file_llm_fine_tune_repository: "s3://$CIRCLECI_AWS_S3_BUCKET/fine_tune_repository"
      dd_trace_enabled: false
      istio_enabled: true
      sensitive_log_mode: false
      tgi_repository: "text-generation-inference"
      vllm_repository: "vllm"
      lightllm_repository: "lightllm"
      tensorrt_llm_repository: "tensorrt-llm"
      batch_infer_vllm_repository: "llm-engine/batch-infer-vllm"
      user_inference_base_repository: "launch/inference"
      user_inference_pytorch_repository: "hosted-model-inference/async-pytorch"
      user_inference_tensorflow_repository: "hosted-model-inference/async-tensorflow-cpu"
      docker_image_layer_cache_repository: "kaniko-cache"
      hf_user_fine_tuned_weights_prefix: "s3://$CIRCLECI_AWS_S3_BUCKET/model-weights"

# Service Account
serviceAccount:
  annotations:
    "eks.amazonaws.com/role-arn": arn:aws:iam::$CIRCLECI_AWS_ACCOUNT_ID:role/default
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-2"
  namespaces:
    - default
    - model-engine

aws:
  configMap:
    name: default-config
    create: false
    mountPath: /opt/.aws/config
  profileName: default
  s3WriteProfileName: default

forwarder:
  forceUseIPv4: true

triton:
  image:
    repository: nvidia/tritonserver
    tag: latest

serviceTemplate:
  securityContext:
    capabilities:
      drop:
        - all
  mountInfraConfig: true
  serviceAccountName: default
  awsConfigMapName: default-config

imageCache:
  devices:
    - name: cpu
      nodeSelector:
        cpu-only: "true"
    - name: a10
      nodeSelector:
        k8s.amazonaws.com/accelerator: nvidia-ampere-a10
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
    - name: a100
      nodeSelector:
        k8s.amazonaws.com/accelerator: nvidia-ampere-a100
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
    - name: t4
      nodeSelector:
        k8s.amazonaws.com/accelerator: nvidia-tesla-t4
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"

celeryBrokerType: redis
